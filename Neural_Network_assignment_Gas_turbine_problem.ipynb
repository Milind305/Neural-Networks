{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Network_assignment_Gas_turbine_problem.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1DIR46FxAhomVqgD2FniihbOVWdw9rHJ1",
      "authorship_tag": "ABX9TyOoRLkaBgPfQHLvbXVwDqfF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Milind305/Neural-Networks/blob/main/Neural_Network_assignment_Gas_turbine_problem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZXsDTV7p-Id"
      },
      "source": [
        "# importing necessary packages\n",
        "import tensorflow as tf\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import keras\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from keras.optimizers import Adam\n"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRDjVH6sqCQl"
      },
      "source": [
        "# Loading dataset\n",
        "turbine_data= pd.read_csv('/content/gas_turbines.csv')"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkTSKvMDuy6m"
      },
      "source": [
        "# copy the data \n",
        "df= turbine_data.copy()"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "VX8IBXLRxuEr",
        "outputId": "6ab55c13-396b-4fc4-c056-9f5f816098dd"
      },
      "source": [
        "# Head of data\n",
        "df.head()"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AT</th>\n",
              "      <th>AP</th>\n",
              "      <th>AH</th>\n",
              "      <th>AFDP</th>\n",
              "      <th>GTEP</th>\n",
              "      <th>TIT</th>\n",
              "      <th>TAT</th>\n",
              "      <th>TEY</th>\n",
              "      <th>CDP</th>\n",
              "      <th>CO</th>\n",
              "      <th>NOX</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.8594</td>\n",
              "      <td>1007.9</td>\n",
              "      <td>96.799</td>\n",
              "      <td>3.5000</td>\n",
              "      <td>19.663</td>\n",
              "      <td>1059.2</td>\n",
              "      <td>550.00</td>\n",
              "      <td>114.70</td>\n",
              "      <td>10.605</td>\n",
              "      <td>3.1547</td>\n",
              "      <td>82.722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.7850</td>\n",
              "      <td>1008.4</td>\n",
              "      <td>97.118</td>\n",
              "      <td>3.4998</td>\n",
              "      <td>19.728</td>\n",
              "      <td>1059.3</td>\n",
              "      <td>550.00</td>\n",
              "      <td>114.72</td>\n",
              "      <td>10.598</td>\n",
              "      <td>3.2363</td>\n",
              "      <td>82.776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.8977</td>\n",
              "      <td>1008.8</td>\n",
              "      <td>95.939</td>\n",
              "      <td>3.4824</td>\n",
              "      <td>19.779</td>\n",
              "      <td>1059.4</td>\n",
              "      <td>549.87</td>\n",
              "      <td>114.71</td>\n",
              "      <td>10.601</td>\n",
              "      <td>3.2012</td>\n",
              "      <td>82.468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.0569</td>\n",
              "      <td>1009.2</td>\n",
              "      <td>95.249</td>\n",
              "      <td>3.4805</td>\n",
              "      <td>19.792</td>\n",
              "      <td>1059.6</td>\n",
              "      <td>549.99</td>\n",
              "      <td>114.72</td>\n",
              "      <td>10.606</td>\n",
              "      <td>3.1923</td>\n",
              "      <td>82.670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.3978</td>\n",
              "      <td>1009.7</td>\n",
              "      <td>95.150</td>\n",
              "      <td>3.4976</td>\n",
              "      <td>19.765</td>\n",
              "      <td>1059.7</td>\n",
              "      <td>549.98</td>\n",
              "      <td>114.72</td>\n",
              "      <td>10.612</td>\n",
              "      <td>3.2484</td>\n",
              "      <td>82.311</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       AT      AP      AH    AFDP  ...     TEY     CDP      CO     NOX\n",
              "0  6.8594  1007.9  96.799  3.5000  ...  114.70  10.605  3.1547  82.722\n",
              "1  6.7850  1008.4  97.118  3.4998  ...  114.72  10.598  3.2363  82.776\n",
              "2  6.8977  1008.8  95.939  3.4824  ...  114.71  10.601  3.2012  82.468\n",
              "3  7.0569  1009.2  95.249  3.4805  ...  114.72  10.606  3.1923  82.670\n",
              "4  7.3978  1009.7  95.150  3.4976  ...  114.72  10.612  3.2484  82.311\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGZxn_EOx1HQ",
        "outputId": "aa0ed044-e75d-4dfb-bcf2-cba61ed97ea3"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15039 entries, 0 to 15038\n",
            "Data columns (total 11 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   AT      15039 non-null  float64\n",
            " 1   AP      15039 non-null  float64\n",
            " 2   AH      15039 non-null  float64\n",
            " 3   AFDP    15039 non-null  float64\n",
            " 4   GTEP    15039 non-null  float64\n",
            " 5   TIT     15039 non-null  float64\n",
            " 6   TAT     15039 non-null  float64\n",
            " 7   TEY     15039 non-null  float64\n",
            " 8   CDP     15039 non-null  float64\n",
            " 9   CO      15039 non-null  float64\n",
            " 10  NOX     15039 non-null  float64\n",
            "dtypes: float64(11)\n",
            "memory usage: 1.3 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "WZqd4ntYev4Z",
        "outputId": "64cc68d6-36ae-4957-a930-d5ec6e991465"
      },
      "source": [
        "# Describe data\n",
        "df"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AT</th>\n",
              "      <th>AP</th>\n",
              "      <th>AH</th>\n",
              "      <th>AFDP</th>\n",
              "      <th>GTEP</th>\n",
              "      <th>TIT</th>\n",
              "      <th>TAT</th>\n",
              "      <th>TEY</th>\n",
              "      <th>CDP</th>\n",
              "      <th>CO</th>\n",
              "      <th>NOX</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.8594</td>\n",
              "      <td>1007.9</td>\n",
              "      <td>96.799</td>\n",
              "      <td>3.5000</td>\n",
              "      <td>19.663</td>\n",
              "      <td>1059.2</td>\n",
              "      <td>550.00</td>\n",
              "      <td>114.70</td>\n",
              "      <td>10.605</td>\n",
              "      <td>3.1547</td>\n",
              "      <td>82.722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.7850</td>\n",
              "      <td>1008.4</td>\n",
              "      <td>97.118</td>\n",
              "      <td>3.4998</td>\n",
              "      <td>19.728</td>\n",
              "      <td>1059.3</td>\n",
              "      <td>550.00</td>\n",
              "      <td>114.72</td>\n",
              "      <td>10.598</td>\n",
              "      <td>3.2363</td>\n",
              "      <td>82.776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.8977</td>\n",
              "      <td>1008.8</td>\n",
              "      <td>95.939</td>\n",
              "      <td>3.4824</td>\n",
              "      <td>19.779</td>\n",
              "      <td>1059.4</td>\n",
              "      <td>549.87</td>\n",
              "      <td>114.71</td>\n",
              "      <td>10.601</td>\n",
              "      <td>3.2012</td>\n",
              "      <td>82.468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.0569</td>\n",
              "      <td>1009.2</td>\n",
              "      <td>95.249</td>\n",
              "      <td>3.4805</td>\n",
              "      <td>19.792</td>\n",
              "      <td>1059.6</td>\n",
              "      <td>549.99</td>\n",
              "      <td>114.72</td>\n",
              "      <td>10.606</td>\n",
              "      <td>3.1923</td>\n",
              "      <td>82.670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.3978</td>\n",
              "      <td>1009.7</td>\n",
              "      <td>95.150</td>\n",
              "      <td>3.4976</td>\n",
              "      <td>19.765</td>\n",
              "      <td>1059.7</td>\n",
              "      <td>549.98</td>\n",
              "      <td>114.72</td>\n",
              "      <td>10.612</td>\n",
              "      <td>3.2484</td>\n",
              "      <td>82.311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15034</th>\n",
              "      <td>9.0301</td>\n",
              "      <td>1005.6</td>\n",
              "      <td>98.460</td>\n",
              "      <td>3.5421</td>\n",
              "      <td>19.164</td>\n",
              "      <td>1049.7</td>\n",
              "      <td>546.21</td>\n",
              "      <td>111.61</td>\n",
              "      <td>10.400</td>\n",
              "      <td>4.5186</td>\n",
              "      <td>79.559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15035</th>\n",
              "      <td>7.8879</td>\n",
              "      <td>1005.9</td>\n",
              "      <td>99.093</td>\n",
              "      <td>3.5059</td>\n",
              "      <td>19.414</td>\n",
              "      <td>1046.3</td>\n",
              "      <td>543.22</td>\n",
              "      <td>111.78</td>\n",
              "      <td>10.433</td>\n",
              "      <td>4.8470</td>\n",
              "      <td>79.917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15036</th>\n",
              "      <td>7.2647</td>\n",
              "      <td>1006.3</td>\n",
              "      <td>99.496</td>\n",
              "      <td>3.4770</td>\n",
              "      <td>19.530</td>\n",
              "      <td>1037.7</td>\n",
              "      <td>537.32</td>\n",
              "      <td>110.19</td>\n",
              "      <td>10.483</td>\n",
              "      <td>7.9632</td>\n",
              "      <td>90.912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15037</th>\n",
              "      <td>7.0060</td>\n",
              "      <td>1006.8</td>\n",
              "      <td>99.008</td>\n",
              "      <td>3.4486</td>\n",
              "      <td>19.377</td>\n",
              "      <td>1043.2</td>\n",
              "      <td>541.24</td>\n",
              "      <td>110.74</td>\n",
              "      <td>10.533</td>\n",
              "      <td>6.2494</td>\n",
              "      <td>93.227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15038</th>\n",
              "      <td>6.9279</td>\n",
              "      <td>1007.2</td>\n",
              "      <td>97.533</td>\n",
              "      <td>3.4275</td>\n",
              "      <td>19.306</td>\n",
              "      <td>1049.9</td>\n",
              "      <td>545.85</td>\n",
              "      <td>111.58</td>\n",
              "      <td>10.583</td>\n",
              "      <td>4.9816</td>\n",
              "      <td>92.498</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15039 rows Ã— 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           AT      AP      AH    AFDP  ...     TEY     CDP      CO     NOX\n",
              "0      6.8594  1007.9  96.799  3.5000  ...  114.70  10.605  3.1547  82.722\n",
              "1      6.7850  1008.4  97.118  3.4998  ...  114.72  10.598  3.2363  82.776\n",
              "2      6.8977  1008.8  95.939  3.4824  ...  114.71  10.601  3.2012  82.468\n",
              "3      7.0569  1009.2  95.249  3.4805  ...  114.72  10.606  3.1923  82.670\n",
              "4      7.3978  1009.7  95.150  3.4976  ...  114.72  10.612  3.2484  82.311\n",
              "...       ...     ...     ...     ...  ...     ...     ...     ...     ...\n",
              "15034  9.0301  1005.6  98.460  3.5421  ...  111.61  10.400  4.5186  79.559\n",
              "15035  7.8879  1005.9  99.093  3.5059  ...  111.78  10.433  4.8470  79.917\n",
              "15036  7.2647  1006.3  99.496  3.4770  ...  110.19  10.483  7.9632  90.912\n",
              "15037  7.0060  1006.8  99.008  3.4486  ...  110.74  10.533  6.2494  93.227\n",
              "15038  6.9279  1007.2  97.533  3.4275  ...  111.58  10.583  4.9816  92.498\n",
              "\n",
              "[15039 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "uoanyN5Ajy6Z",
        "outputId": "60f170fb-243f-4720-ad75-b980f130bc95"
      },
      "source": [
        "# Describe data\n",
        "df.describe()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AT</th>\n",
              "      <th>AP</th>\n",
              "      <th>AH</th>\n",
              "      <th>AFDP</th>\n",
              "      <th>GTEP</th>\n",
              "      <th>TIT</th>\n",
              "      <th>TAT</th>\n",
              "      <th>TEY</th>\n",
              "      <th>CDP</th>\n",
              "      <th>CO</th>\n",
              "      <th>NOX</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>15039.000000</td>\n",
              "      <td>15039.00000</td>\n",
              "      <td>15039.000000</td>\n",
              "      <td>15039.000000</td>\n",
              "      <td>15039.000000</td>\n",
              "      <td>15039.000000</td>\n",
              "      <td>15039.000000</td>\n",
              "      <td>15039.000000</td>\n",
              "      <td>15039.000000</td>\n",
              "      <td>15039.000000</td>\n",
              "      <td>15039.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>17.764381</td>\n",
              "      <td>1013.19924</td>\n",
              "      <td>79.124174</td>\n",
              "      <td>4.200294</td>\n",
              "      <td>25.419061</td>\n",
              "      <td>1083.798770</td>\n",
              "      <td>545.396183</td>\n",
              "      <td>134.188464</td>\n",
              "      <td>12.102353</td>\n",
              "      <td>1.972499</td>\n",
              "      <td>68.190934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7.574323</td>\n",
              "      <td>6.41076</td>\n",
              "      <td>13.793439</td>\n",
              "      <td>0.760197</td>\n",
              "      <td>4.173916</td>\n",
              "      <td>16.527806</td>\n",
              "      <td>7.866803</td>\n",
              "      <td>15.829717</td>\n",
              "      <td>1.103196</td>\n",
              "      <td>2.222206</td>\n",
              "      <td>10.470586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.522300</td>\n",
              "      <td>985.85000</td>\n",
              "      <td>30.344000</td>\n",
              "      <td>2.087400</td>\n",
              "      <td>17.878000</td>\n",
              "      <td>1000.800000</td>\n",
              "      <td>512.450000</td>\n",
              "      <td>100.170000</td>\n",
              "      <td>9.904400</td>\n",
              "      <td>0.000388</td>\n",
              "      <td>27.765000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>11.408000</td>\n",
              "      <td>1008.90000</td>\n",
              "      <td>69.750000</td>\n",
              "      <td>3.723900</td>\n",
              "      <td>23.294000</td>\n",
              "      <td>1079.600000</td>\n",
              "      <td>542.170000</td>\n",
              "      <td>127.985000</td>\n",
              "      <td>11.622000</td>\n",
              "      <td>0.858055</td>\n",
              "      <td>61.303500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>18.186000</td>\n",
              "      <td>1012.80000</td>\n",
              "      <td>82.266000</td>\n",
              "      <td>4.186200</td>\n",
              "      <td>25.082000</td>\n",
              "      <td>1088.700000</td>\n",
              "      <td>549.890000</td>\n",
              "      <td>133.780000</td>\n",
              "      <td>12.025000</td>\n",
              "      <td>1.390200</td>\n",
              "      <td>66.601000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>23.862500</td>\n",
              "      <td>1016.90000</td>\n",
              "      <td>90.043500</td>\n",
              "      <td>4.550900</td>\n",
              "      <td>27.184000</td>\n",
              "      <td>1096.000000</td>\n",
              "      <td>550.060000</td>\n",
              "      <td>140.895000</td>\n",
              "      <td>12.578000</td>\n",
              "      <td>2.160400</td>\n",
              "      <td>73.935500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>34.929000</td>\n",
              "      <td>1034.20000</td>\n",
              "      <td>100.200000</td>\n",
              "      <td>7.610600</td>\n",
              "      <td>37.402000</td>\n",
              "      <td>1100.800000</td>\n",
              "      <td>550.610000</td>\n",
              "      <td>174.610000</td>\n",
              "      <td>15.081000</td>\n",
              "      <td>44.103000</td>\n",
              "      <td>119.890000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 AT           AP  ...            CO           NOX\n",
              "count  15039.000000  15039.00000  ...  15039.000000  15039.000000\n",
              "mean      17.764381   1013.19924  ...      1.972499     68.190934\n",
              "std        7.574323      6.41076  ...      2.222206     10.470586\n",
              "min        0.522300    985.85000  ...      0.000388     27.765000\n",
              "25%       11.408000   1008.90000  ...      0.858055     61.303500\n",
              "50%       18.186000   1012.80000  ...      1.390200     66.601000\n",
              "75%       23.862500   1016.90000  ...      2.160400     73.935500\n",
              "max       34.929000   1034.20000  ...     44.103000    119.890000\n",
              "\n",
              "[8 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsiYF-0Cj90Q",
        "outputId": "56391b1d-7376-43ae-b394-fac53925b0a6"
      },
      "source": [
        "# Checking for null values\n",
        "df.isnull().sum()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AT      0\n",
              "AP      0\n",
              "AH      0\n",
              "AFDP    0\n",
              "GTEP    0\n",
              "TIT     0\n",
              "TAT     0\n",
              "TEY     0\n",
              "CDP     0\n",
              "CO      0\n",
              "NOX     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "id": "yUUZb7Xgk4LN",
        "outputId": "ede0365f-c39b-4c7e-f854-5b5ee8f81c56"
      },
      "source": [
        "df.hist(figsize= (12,10))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fd1452e69d0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd1452f9390>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd14524a350>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fd1451fb9d0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd14521a950>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd14516d210>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fd14511f810>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd14514fcd0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd14514fd10>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fd14510d3d0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd145072dd0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd145034390>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x720 with 12 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "iq4BkOWjlF5K",
        "outputId": "0cf3c837-fd39-40b1-9fd0-0d85e7062703"
      },
      "source": [
        "# Correlation between variables\n",
        "c= df.corr()\n",
        "sns.heatmap(c, vmax=1, square=True)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd137bcb910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAY5037lm8jC",
        "outputId": "8531eadd-10d0-4c26-b023-b108b5ddf3a7"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['AT', 'AP', 'AH', 'AFDP', 'GTEP', 'TIT', 'TAT', 'TEY', 'CDP', 'CO',\n",
              "       'NOX'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPl78DNXsaUE",
        "outputId": "b295e483-4de9-4ff2-b910-cabb3a03f63c"
      },
      "source": [
        "# separating independant and dependant variables\n",
        "x= df[['AT', 'AP', 'AH', 'AFDP', 'GTEP', 'TIT', 'TAT', 'CDP', 'CO', 'NOX']]\n",
        "print(x)\n",
        "y= df['TEY']\n",
        "print(y)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           AT      AP      AH    AFDP  ...     TAT     CDP      CO     NOX\n",
            "0      6.8594  1007.9  96.799  3.5000  ...  550.00  10.605  3.1547  82.722\n",
            "1      6.7850  1008.4  97.118  3.4998  ...  550.00  10.598  3.2363  82.776\n",
            "2      6.8977  1008.8  95.939  3.4824  ...  549.87  10.601  3.2012  82.468\n",
            "3      7.0569  1009.2  95.249  3.4805  ...  549.99  10.606  3.1923  82.670\n",
            "4      7.3978  1009.7  95.150  3.4976  ...  549.98  10.612  3.2484  82.311\n",
            "...       ...     ...     ...     ...  ...     ...     ...     ...     ...\n",
            "15034  9.0301  1005.6  98.460  3.5421  ...  546.21  10.400  4.5186  79.559\n",
            "15035  7.8879  1005.9  99.093  3.5059  ...  543.22  10.433  4.8470  79.917\n",
            "15036  7.2647  1006.3  99.496  3.4770  ...  537.32  10.483  7.9632  90.912\n",
            "15037  7.0060  1006.8  99.008  3.4486  ...  541.24  10.533  6.2494  93.227\n",
            "15038  6.9279  1007.2  97.533  3.4275  ...  545.85  10.583  4.9816  92.498\n",
            "\n",
            "[15039 rows x 10 columns]\n",
            "0        114.70\n",
            "1        114.72\n",
            "2        114.71\n",
            "3        114.72\n",
            "4        114.72\n",
            "          ...  \n",
            "15034    111.61\n",
            "15035    111.78\n",
            "15036    110.19\n",
            "15037    110.74\n",
            "15038    111.58\n",
            "Name: TEY, Length: 15039, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjScf7ggSMVN"
      },
      "source": [
        "# Standerdize the independant variables\n",
        "x_standerdized= (x-x.mean())/x.std()"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "CLGksizeSiLK",
        "outputId": "f020ce6c-c647-4baa-cb22-1c059a1ea5cc"
      },
      "source": [
        "x_standerdized"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AT</th>\n",
              "      <th>AP</th>\n",
              "      <th>AH</th>\n",
              "      <th>AFDP</th>\n",
              "      <th>GTEP</th>\n",
              "      <th>TIT</th>\n",
              "      <th>TAT</th>\n",
              "      <th>CDP</th>\n",
              "      <th>CO</th>\n",
              "      <th>NOX</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.439730</td>\n",
              "      <td>-0.826616</td>\n",
              "      <td>1.281394</td>\n",
              "      <td>-0.921201</td>\n",
              "      <td>-1.379055</td>\n",
              "      <td>-1.488326</td>\n",
              "      <td>0.585221</td>\n",
              "      <td>-1.357286</td>\n",
              "      <td>0.531994</td>\n",
              "      <td>1.387799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.449553</td>\n",
              "      <td>-0.748623</td>\n",
              "      <td>1.304521</td>\n",
              "      <td>-0.921464</td>\n",
              "      <td>-1.363482</td>\n",
              "      <td>-1.482276</td>\n",
              "      <td>0.585221</td>\n",
              "      <td>-1.363631</td>\n",
              "      <td>0.568715</td>\n",
              "      <td>1.392956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.434674</td>\n",
              "      <td>-0.686227</td>\n",
              "      <td>1.219045</td>\n",
              "      <td>-0.944353</td>\n",
              "      <td>-1.351264</td>\n",
              "      <td>-1.476226</td>\n",
              "      <td>0.568696</td>\n",
              "      <td>-1.360911</td>\n",
              "      <td>0.552919</td>\n",
              "      <td>1.363540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.413655</td>\n",
              "      <td>-0.623832</td>\n",
              "      <td>1.169021</td>\n",
              "      <td>-0.946853</td>\n",
              "      <td>-1.348149</td>\n",
              "      <td>-1.464125</td>\n",
              "      <td>0.583950</td>\n",
              "      <td>-1.356379</td>\n",
              "      <td>0.548914</td>\n",
              "      <td>1.382832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.368648</td>\n",
              "      <td>-0.545839</td>\n",
              "      <td>1.161844</td>\n",
              "      <td>-0.924358</td>\n",
              "      <td>-1.354618</td>\n",
              "      <td>-1.458074</td>\n",
              "      <td>0.582678</td>\n",
              "      <td>-1.350940</td>\n",
              "      <td>0.574160</td>\n",
              "      <td>1.348546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15034</th>\n",
              "      <td>-1.153144</td>\n",
              "      <td>-1.185388</td>\n",
              "      <td>1.401813</td>\n",
              "      <td>-0.865821</td>\n",
              "      <td>-1.498607</td>\n",
              "      <td>-2.063115</td>\n",
              "      <td>0.103449</td>\n",
              "      <td>-1.543109</td>\n",
              "      <td>1.145754</td>\n",
              "      <td>1.085714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15035</th>\n",
              "      <td>-1.303943</td>\n",
              "      <td>-1.138592</td>\n",
              "      <td>1.447705</td>\n",
              "      <td>-0.913440</td>\n",
              "      <td>-1.438712</td>\n",
              "      <td>-2.268829</td>\n",
              "      <td>-0.276629</td>\n",
              "      <td>-1.513196</td>\n",
              "      <td>1.293535</td>\n",
              "      <td>1.119905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15036</th>\n",
              "      <td>-1.386220</td>\n",
              "      <td>-1.076197</td>\n",
              "      <td>1.476921</td>\n",
              "      <td>-0.951457</td>\n",
              "      <td>-1.410920</td>\n",
              "      <td>-2.789165</td>\n",
              "      <td>-1.026616</td>\n",
              "      <td>-1.467873</td>\n",
              "      <td>2.695835</td>\n",
              "      <td>2.169990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15037</th>\n",
              "      <td>-1.420375</td>\n",
              "      <td>-0.998203</td>\n",
              "      <td>1.441542</td>\n",
              "      <td>-0.988815</td>\n",
              "      <td>-1.447576</td>\n",
              "      <td>-2.456392</td>\n",
              "      <td>-0.528319</td>\n",
              "      <td>-1.422551</td>\n",
              "      <td>1.924619</td>\n",
              "      <td>2.391085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15038</th>\n",
              "      <td>-1.430687</td>\n",
              "      <td>-0.935808</td>\n",
              "      <td>1.334607</td>\n",
              "      <td>-1.016571</td>\n",
              "      <td>-1.464587</td>\n",
              "      <td>-2.051015</td>\n",
              "      <td>0.057688</td>\n",
              "      <td>-1.377228</td>\n",
              "      <td>1.354105</td>\n",
              "      <td>2.321462</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15039 rows Ã— 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             AT        AP        AH  ...       CDP        CO       NOX\n",
              "0     -1.439730 -0.826616  1.281394  ... -1.357286  0.531994  1.387799\n",
              "1     -1.449553 -0.748623  1.304521  ... -1.363631  0.568715  1.392956\n",
              "2     -1.434674 -0.686227  1.219045  ... -1.360911  0.552919  1.363540\n",
              "3     -1.413655 -0.623832  1.169021  ... -1.356379  0.548914  1.382832\n",
              "4     -1.368648 -0.545839  1.161844  ... -1.350940  0.574160  1.348546\n",
              "...         ...       ...       ...  ...       ...       ...       ...\n",
              "15034 -1.153144 -1.185388  1.401813  ... -1.543109  1.145754  1.085714\n",
              "15035 -1.303943 -1.138592  1.447705  ... -1.513196  1.293535  1.119905\n",
              "15036 -1.386220 -1.076197  1.476921  ... -1.467873  2.695835  2.169990\n",
              "15037 -1.420375 -0.998203  1.441542  ... -1.422551  1.924619  2.391085\n",
              "15038 -1.430687 -0.935808  1.334607  ... -1.377228  1.354105  2.321462\n",
              "\n",
              "[15039 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToGjZYM9uP7D"
      },
      "source": [
        "# Tunig hyperparameters- Batch size and epochs\n",
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHEmOCQBydyU"
      },
      "source": [
        "# create a sequential model\n",
        "def create_model():\n",
        "  model= Sequential()\n",
        "  model.add(Dense(10, input_dim=10, kernel_initializer= 'normal', activation='relu'))\n",
        "  model.add(Dense(8, kernel_initializer= 'normal', activation='relu'))\n",
        "  model.add(Dense(8, kernel_initializer= 'normal', activation='relu'))\n",
        "  model.add(Dense(1, kernel_initializer= 'normal')) \n",
        "  adam= Adam()\n",
        "# Compile model\n",
        "  model.compile(loss='mean_squared_error', optimizer=adam)\n",
        "  return model"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQ-DFbdsi-wP",
        "outputId": "d51e26c5-f502-41d9-9760-ed4c4f4b4b19"
      },
      "source": [
        "# create regression model\n",
        "model= KerasRegressor(build_fn=create_model, verbose=0)\n",
        "# create grid search model\n",
        "batch_size=[50,100, 200, 400, 800, 1000]\n",
        "epochs=[10,50,100]\n",
        "# Make a dictionary of grid search parameters\n",
        "param_grid= dict(batch_size= batch_size, epochs=epochs)\n",
        "#build and fit the gridsearchCV\n",
        "grid= GridSearchCV(estimator=model, param_grid=param_grid, cv= KFold(), verbose=10 )\n",
        "grid_result= grid.fit(x_standerdized,y)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
            "[CV] batch_size=50, epochs=10 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ......... batch_size=50, epochs=10, score=-255.557, total=   2.7s\n",
            "[CV] batch_size=50, epochs=10 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .......... batch_size=50, epochs=10, score=-27.035, total=   2.7s\n",
            "[CV] batch_size=50, epochs=10 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    5.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .......... batch_size=50, epochs=10, score=-52.409, total=   2.8s\n",
            "[CV] batch_size=50, epochs=10 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    8.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .......... batch_size=50, epochs=10, score=-56.008, total=   2.7s\n",
            "[CV] batch_size=50, epochs=10 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   10.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .......... batch_size=50, epochs=10, score=-81.963, total=   3.0s\n",
            "[CV] batch_size=50, epochs=50 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ........... batch_size=50, epochs=50, score=-0.915, total=  11.0s\n",
            "[CV] batch_size=50, epochs=50 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   24.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ........... batch_size=50, epochs=50, score=-0.458, total=  11.1s\n",
            "[CV] batch_size=50, epochs=50 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   35.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ........... batch_size=50, epochs=50, score=-1.167, total=  11.2s\n",
            "[CV] batch_size=50, epochs=50 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   47.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ........... batch_size=50, epochs=50, score=-0.533, total=  11.3s\n",
            "[CV] batch_size=50, epochs=50 ........................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   58.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ........... batch_size=50, epochs=50, score=-0.916, total=  11.0s\n",
            "[CV] batch_size=50, epochs=100 .......................................\n",
            "[CV] .......... batch_size=50, epochs=100, score=-0.776, total=  21.4s\n",
            "[CV] batch_size=50, epochs=100 .......................................\n",
            "[CV] .......... batch_size=50, epochs=100, score=-0.462, total=  21.7s\n",
            "[CV] batch_size=50, epochs=100 .......................................\n",
            "[CV] .......... batch_size=50, epochs=100, score=-0.823, total=  21.6s\n",
            "[CV] batch_size=50, epochs=100 .......................................\n",
            "[CV] .......... batch_size=50, epochs=100, score=-0.614, total=  21.4s\n",
            "[CV] batch_size=50, epochs=100 .......................................\n",
            "[CV] .......... batch_size=50, epochs=100, score=-0.963, total=  21.8s\n",
            "[CV] batch_size=100, epochs=10 .......................................\n",
            "[CV] ........ batch_size=100, epochs=10, score=-321.318, total=   1.6s\n",
            "[CV] batch_size=100, epochs=10 .......................................\n",
            "[CV] ........ batch_size=100, epochs=10, score=-420.771, total=   1.6s\n",
            "[CV] batch_size=100, epochs=10 .......................................\n",
            "[CV] ........ batch_size=100, epochs=10, score=-276.994, total=   1.7s\n",
            "[CV] batch_size=100, epochs=10 .......................................\n",
            "[CV] ........ batch_size=100, epochs=10, score=-116.522, total=   2.0s\n",
            "[CV] batch_size=100, epochs=10 .......................................\n",
            "[CV] ........ batch_size=100, epochs=10, score=-137.511, total=   1.7s\n",
            "[CV] batch_size=100, epochs=50 .......................................\n",
            "[CV] .......... batch_size=100, epochs=50, score=-5.292, total=   6.1s\n",
            "[CV] batch_size=100, epochs=50 .......................................\n",
            "[CV] .......... batch_size=100, epochs=50, score=-0.649, total=   6.1s\n",
            "[CV] batch_size=100, epochs=50 .......................................\n",
            "[CV] .......... batch_size=100, epochs=50, score=-1.933, total=   5.9s\n",
            "[CV] batch_size=100, epochs=50 .......................................\n",
            "[CV] .......... batch_size=100, epochs=50, score=-4.204, total=   6.0s\n",
            "[CV] batch_size=100, epochs=50 .......................................\n",
            "[CV] .......... batch_size=100, epochs=50, score=-1.478, total=   6.0s\n",
            "[CV] batch_size=100, epochs=100 ......................................\n",
            "[CV] ......... batch_size=100, epochs=100, score=-0.836, total=  11.3s\n",
            "[CV] batch_size=100, epochs=100 ......................................\n",
            "[CV] ......... batch_size=100, epochs=100, score=-0.560, total=  11.4s\n",
            "[CV] batch_size=100, epochs=100 ......................................\n",
            "[CV] ......... batch_size=100, epochs=100, score=-0.690, total=  11.4s\n",
            "[CV] batch_size=100, epochs=100 ......................................\n",
            "[CV] ......... batch_size=100, epochs=100, score=-0.741, total=  11.3s\n",
            "[CV] batch_size=100, epochs=100 ......................................\n",
            "[CV] ......... batch_size=100, epochs=100, score=-0.693, total=  11.3s\n",
            "[CV] batch_size=200, epochs=10 .......................................\n",
            "[CV] ........ batch_size=200, epochs=10, score=-789.312, total=   1.5s\n",
            "[CV] batch_size=200, epochs=10 .......................................\n",
            "[CV] ........ batch_size=200, epochs=10, score=-875.644, total=   1.1s\n",
            "[CV] batch_size=200, epochs=10 .......................................\n",
            "[CV] ....... batch_size=200, epochs=10, score=-1221.185, total=   1.1s\n",
            "[CV] batch_size=200, epochs=10 .......................................\n",
            "[CV] ........ batch_size=200, epochs=10, score=-522.656, total=   1.1s\n",
            "[CV] batch_size=200, epochs=10 .......................................\n",
            "[CV] ........ batch_size=200, epochs=10, score=-335.621, total=   1.1s\n",
            "[CV] batch_size=200, epochs=50 .......................................\n",
            "[CV] ......... batch_size=200, epochs=50, score=-59.474, total=   3.4s\n",
            "[CV] batch_size=200, epochs=50 .......................................\n",
            "[CV] ......... batch_size=200, epochs=50, score=-13.302, total=   3.4s\n",
            "[CV] batch_size=200, epochs=50 .......................................\n",
            "[CV] ......... batch_size=200, epochs=50, score=-23.526, total=   3.4s\n",
            "[CV] batch_size=200, epochs=50 .......................................\n",
            "[CV] ......... batch_size=200, epochs=50, score=-19.392, total=   3.4s\n",
            "[CV] batch_size=200, epochs=50 .......................................\n",
            "[CV] ......... batch_size=200, epochs=50, score=-15.195, total=   3.3s\n",
            "[CV] batch_size=200, epochs=100 ......................................\n",
            "[CV] ......... batch_size=200, epochs=100, score=-3.368, total=   6.3s\n",
            "[CV] batch_size=200, epochs=100 ......................................\n",
            "[CV] ......... batch_size=200, epochs=100, score=-1.598, total=   6.2s\n",
            "[CV] batch_size=200, epochs=100 ......................................\n",
            "[CV] ......... batch_size=200, epochs=100, score=-0.956, total=   6.2s\n",
            "[CV] batch_size=200, epochs=100 ......................................\n",
            "[CV] ......... batch_size=200, epochs=100, score=-1.304, total=   6.6s\n",
            "[CV] batch_size=200, epochs=100 ......................................\n",
            "[CV] ......... batch_size=200, epochs=100, score=-1.048, total=   6.2s\n",
            "[CV] batch_size=400, epochs=10 .......................................\n",
            "[CV] ....... batch_size=400, epochs=10, score=-5866.156, total=   0.8s\n",
            "[CV] batch_size=400, epochs=10 .......................................\n",
            "[CV] ....... batch_size=400, epochs=10, score=-6658.998, total=   0.8s\n",
            "[CV] batch_size=400, epochs=10 .......................................\n",
            "[CV] ....... batch_size=400, epochs=10, score=-6213.161, total=   0.8s\n",
            "[CV] batch_size=400, epochs=10 .......................................\n",
            "[CV] ....... batch_size=400, epochs=10, score=-3472.333, total=   0.8s\n",
            "[CV] batch_size=400, epochs=10 .......................................\n",
            "[CV] ....... batch_size=400, epochs=10, score=-3756.173, total=   0.8s\n",
            "[CV] batch_size=400, epochs=50 .......................................\n",
            "[CV] ........ batch_size=400, epochs=50, score=-203.500, total=   2.0s\n",
            "[CV] batch_size=400, epochs=50 .......................................\n",
            "[CV] ........ batch_size=400, epochs=50, score=-139.908, total=   2.1s\n",
            "[CV] batch_size=400, epochs=50 .......................................\n",
            "[CV] ........ batch_size=400, epochs=50, score=-137.673, total=   2.1s\n",
            "[CV] batch_size=400, epochs=50 .......................................\n",
            "[CV] ........ batch_size=400, epochs=50, score=-115.955, total=   2.1s\n",
            "[CV] batch_size=400, epochs=50 .......................................\n",
            "[CV] ........ batch_size=400, epochs=50, score=-106.749, total=   2.1s\n",
            "[CV] batch_size=400, epochs=100 ......................................\n",
            "[CV] ........ batch_size=400, epochs=100, score=-42.409, total=   3.6s\n",
            "[CV] batch_size=400, epochs=100 ......................................\n",
            "[CV] ......... batch_size=400, epochs=100, score=-9.715, total=   3.6s\n",
            "[CV] batch_size=400, epochs=100 ......................................\n",
            "[CV] ........ batch_size=400, epochs=100, score=-18.406, total=   3.9s\n",
            "[CV] batch_size=400, epochs=100 ......................................\n",
            "[CV] ........ batch_size=400, epochs=100, score=-22.788, total=   3.6s\n",
            "[CV] batch_size=400, epochs=100 ......................................\n",
            "[CV] ........ batch_size=400, epochs=100, score=-18.801, total=   3.6s\n",
            "[CV] batch_size=800, epochs=10 .......................................\n",
            "[CV] ...... batch_size=800, epochs=10, score=-16271.437, total=   0.7s\n",
            "[CV] batch_size=800, epochs=10 .......................................\n",
            "[CV] ...... batch_size=800, epochs=10, score=-16327.524, total=   0.7s\n",
            "[CV] batch_size=800, epochs=10 .......................................\n",
            "[CV] ...... batch_size=800, epochs=10, score=-17650.861, total=   0.7s\n",
            "[CV] batch_size=800, epochs=10 .......................................\n",
            "[CV] ...... batch_size=800, epochs=10, score=-16759.916, total=   0.7s\n",
            "[CV] batch_size=800, epochs=10 .......................................\n",
            "[CV] ...... batch_size=800, epochs=10, score=-15494.002, total=   0.7s\n",
            "[CV] batch_size=800, epochs=50 .......................................\n",
            "[CV] ........ batch_size=800, epochs=50, score=-551.214, total=   1.4s\n",
            "[CV] batch_size=800, epochs=50 .......................................\n",
            "[CV] ........ batch_size=800, epochs=50, score=-505.176, total=   1.4s\n",
            "[CV] batch_size=800, epochs=50 .......................................\n",
            "[CV] ........ batch_size=800, epochs=50, score=-502.566, total=   1.4s\n",
            "[CV] batch_size=800, epochs=50 .......................................\n",
            "[CV] ........ batch_size=800, epochs=50, score=-312.163, total=   1.4s\n",
            "[CV] batch_size=800, epochs=50 .......................................\n",
            "[CV] ........ batch_size=800, epochs=50, score=-212.576, total=   1.7s\n",
            "[CV] batch_size=800, epochs=100 ......................................\n",
            "[CV] ....... batch_size=800, epochs=100, score=-235.699, total=   2.2s\n",
            "[CV] batch_size=800, epochs=100 ......................................\n",
            "[CV] ........ batch_size=800, epochs=100, score=-99.499, total=   2.2s\n",
            "[CV] batch_size=800, epochs=100 ......................................\n",
            "[CV] ....... batch_size=800, epochs=100, score=-123.227, total=   2.2s\n",
            "[CV] batch_size=800, epochs=100 ......................................\n",
            "[CV] ....... batch_size=800, epochs=100, score=-113.802, total=   2.2s\n",
            "[CV] batch_size=800, epochs=100 ......................................\n",
            "[CV] ........ batch_size=800, epochs=100, score=-86.329, total=   2.2s\n",
            "[CV] batch_size=1000, epochs=10 ......................................\n",
            "[CV] ..... batch_size=1000, epochs=10, score=-18335.197, total=   0.7s\n",
            "[CV] batch_size=1000, epochs=10 ......................................\n",
            "[CV] ..... batch_size=1000, epochs=10, score=-16390.479, total=   0.7s\n",
            "[CV] batch_size=1000, epochs=10 ......................................\n",
            "[CV] ..... batch_size=1000, epochs=10, score=-18994.721, total=   0.7s\n",
            "[CV] batch_size=1000, epochs=10 ......................................\n",
            "[CV] ..... batch_size=1000, epochs=10, score=-18113.908, total=   0.7s\n",
            "[CV] batch_size=1000, epochs=10 ......................................\n",
            "[CV] ..... batch_size=1000, epochs=10, score=-16642.541, total=   0.7s\n",
            "[CV] batch_size=1000, epochs=50 ......................................\n",
            "[CV] ....... batch_size=1000, epochs=50, score=-885.289, total=   1.2s\n",
            "[CV] batch_size=1000, epochs=50 ......................................\n",
            "[CV] ...... batch_size=1000, epochs=50, score=-1883.261, total=   1.2s\n",
            "[CV] batch_size=1000, epochs=50 ......................................\n",
            "[CV] ....... batch_size=1000, epochs=50, score=-497.885, total=   1.6s\n",
            "[CV] batch_size=1000, epochs=50 ......................................\n",
            "[CV] ....... batch_size=1000, epochs=50, score=-479.481, total=   1.3s\n",
            "[CV] batch_size=1000, epochs=50 ......................................\n",
            "[CV] ....... batch_size=1000, epochs=50, score=-307.220, total=   1.3s\n",
            "[CV] batch_size=1000, epochs=100 .....................................\n",
            "[CV] ...... batch_size=1000, epochs=100, score=-336.678, total=   2.0s\n",
            "[CV] batch_size=1000, epochs=100 .....................................\n",
            "[CV] ...... batch_size=1000, epochs=100, score=-150.853, total=   2.0s\n",
            "[CV] batch_size=1000, epochs=100 .....................................\n",
            "[CV] ...... batch_size=1000, epochs=100, score=-245.225, total=   2.0s\n",
            "[CV] batch_size=1000, epochs=100 .....................................\n",
            "[CV] ...... batch_size=1000, epochs=100, score=-204.526, total=   2.0s\n",
            "[CV] batch_size=1000, epochs=100 .....................................\n",
            "[CV] ...... batch_size=1000, epochs=100, score=-105.842, total=   2.0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed:  6.7min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwlQRZdPmN2M",
        "outputId": "9e279552-c694-43fa-b36c-378d34ed2e6b"
      },
      "source": [
        "# summerize results\n",
        "print('Best:{}, using {}'.format(grid_result.best_score_, grid_result.best_params_))\n",
        "means= grid_result.cv_results_['mean_test_score']\n",
        "stds= grid_result.cv_results_['std_test_score']\n",
        "params= grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best:-0.7039520859718322, using {'batch_size': 100, 'epochs': 100}\n",
            "-94.59455146789551,82.342196051359 with: {'batch_size': 50, 'epochs': 10}\n",
            "-0.7979467153549195,0.26469448434439774 with: {'batch_size': 50, 'epochs': 50}\n",
            "-0.7273344576358796,0.17336543410704175 with: {'batch_size': 50, 'epochs': 100}\n",
            "-254.62334747314452,114.31618427834505 with: {'batch_size': 100, 'epochs': 10}\n",
            "-2.7111358761787416,1.7475926632434546 with: {'batch_size': 100, 'epochs': 50}\n",
            "-0.7039520859718322,0.08905221926371942 with: {'batch_size': 100, 'epochs': 100}\n",
            "-748.8835021972657,304.21579889349374 with: {'batch_size': 200, 'epochs': 10}\n",
            "-26.177952766418457,17.018102486481745 with: {'batch_size': 200, 'epochs': 50}\n",
            "-1.6544944882392882,0.8851990213204778 with: {'batch_size': 200, 'epochs': 100}\n",
            "-5193.364208984375,1316.6765387202865 with: {'batch_size': 400, 'epochs': 10}\n",
            "-140.75717468261718,33.8190370519572 with: {'batch_size': 400, 'epochs': 50}\n",
            "-22.424056625366212,10.865785830181698 with: {'batch_size': 400, 'epochs': 100}\n",
            "-16500.748046875,705.1321145374834 with: {'batch_size': 800, 'epochs': 10}\n",
            "-416.73894958496095,131.06418931353267 with: {'batch_size': 800, 'epochs': 50}\n",
            "-131.71118927001953,53.48536194763666 with: {'batch_size': 800, 'epochs': 100}\n",
            "-17695.369140625,1008.370573088534 with: {'batch_size': 1000, 'epochs': 10}\n",
            "-810.6274719238281,568.682850296579 with: {'batch_size': 1000, 'epochs': 50}\n",
            "-208.6250747680664,79.5687574193448 with: {'batch_size': 1000, 'epochs': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2Ot9O448KEb",
        "outputId": "ebc3ee90-9900-4ed9-e3a3-78a2c85be95f"
      },
      "source": [
        "# Tuning hyperparameter: Learning rate and drop out rate\n",
        "from keras.layers import Dropout\n",
        "\n",
        "# defining model\n",
        "def create_model_lr_drate(learning_rate,dropout_rate):\n",
        "  model= Sequential()\n",
        "  model.add(Dense(10, input_dim=10, kernel_initializer= 'normal', activation='relu'))\n",
        "  model.add(Dropout(dropout_rate))\n",
        "  model.add(Dense(8, kernel_initializer= 'normal', activation='relu'))\n",
        "  model.add(Dropout(dropout_rate))\n",
        "  model.add(Dense(8, kernel_initializer= 'normal', activation='relu'))\n",
        "  model.add(Dropout(dropout_rate))\n",
        "  model.add(Dense(1, kernel_initializer= 'normal')) \n",
        "  adam= Adam(learning_rate= learning_rate)\n",
        "# Compile model\n",
        "  model.compile(loss='mean_squared_error', optimizer=adam)\n",
        "  return model\n",
        "\n",
        "# Define regression model\n",
        "model= KerasRegressor(build_fn=create_model_lr_drate, verbose=0, batch_size=100, epochs=100)\n",
        "# Define grid search model\n",
        "learning_rate=[0.001, 0.01, 0.1, 0.2, 0.5]\n",
        "dropout_rate=[0, 0.1, 0.2]\n",
        "# Make a dictionary of grid search parameters\n",
        "param_grid= dict(learning_rate= learning_rate, dropout_rate=dropout_rate)\n",
        "#build and fit the gridsearchCV\n",
        "grid= GridSearchCV(estimator=model, param_grid=param_grid, cv= KFold(), verbose=10 )\n",
        "grid_result= grid.fit(x_standerdized,y)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
            "[CV] dropout_rate=0, learning_rate=0.001 .............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0, learning_rate=0.001, score=-0.772, total=  12.6s\n",
            "[CV] dropout_rate=0, learning_rate=0.001 .............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0, learning_rate=0.001, score=-0.405, total=  12.1s\n",
            "[CV] dropout_rate=0, learning_rate=0.001 .............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   24.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0, learning_rate=0.001, score=-0.681, total=  12.1s\n",
            "[CV] dropout_rate=0, learning_rate=0.001 .............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   36.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0, learning_rate=0.001, score=-0.480, total=  12.2s\n",
            "[CV] dropout_rate=0, learning_rate=0.001 .............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   49.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0, learning_rate=0.001, score=-0.763, total=  12.1s\n",
            "[CV] dropout_rate=0, learning_rate=0.01 ..............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.0min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] . dropout_rate=0, learning_rate=0.01, score=-1.407, total=  12.1s\n",
            "[CV] dropout_rate=0, learning_rate=0.01 ..............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.2min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] . dropout_rate=0, learning_rate=0.01, score=-0.427, total=  12.2s\n",
            "[CV] dropout_rate=0, learning_rate=0.01 ..............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  1.4min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] . dropout_rate=0, learning_rate=0.01, score=-0.513, total=  12.2s\n",
            "[CV] dropout_rate=0, learning_rate=0.01 ..............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  1.6min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] . dropout_rate=0, learning_rate=0.01, score=-0.606, total=  12.4s\n",
            "[CV] dropout_rate=0, learning_rate=0.01 ..............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.8min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] . dropout_rate=0, learning_rate=0.01, score=-1.515, total=  12.1s\n",
            "[CV] dropout_rate=0, learning_rate=0.1 ...............................\n",
            "[CV] .. dropout_rate=0, learning_rate=0.1, score=-0.764, total=  12.1s\n",
            "[CV] dropout_rate=0, learning_rate=0.1 ...............................\n",
            "[CV] .. dropout_rate=0, learning_rate=0.1, score=-0.871, total=  12.6s\n",
            "[CV] dropout_rate=0, learning_rate=0.1 ...............................\n",
            "[CV] .. dropout_rate=0, learning_rate=0.1, score=-4.191, total=  11.8s\n",
            "[CV] dropout_rate=0, learning_rate=0.1 ...............................\n",
            "[CV] .. dropout_rate=0, learning_rate=0.1, score=-2.319, total=  12.2s\n",
            "[CV] dropout_rate=0, learning_rate=0.1 ...............................\n",
            "[CV] .. dropout_rate=0, learning_rate=0.1, score=-0.872, total=  12.2s\n",
            "[CV] dropout_rate=0, learning_rate=0.2 ...............................\n",
            "[CV] .. dropout_rate=0, learning_rate=0.2, score=-0.852, total=  12.3s\n",
            "[CV] dropout_rate=0, learning_rate=0.2 ...............................\n",
            "[CV] .. dropout_rate=0, learning_rate=0.2, score=-0.476, total=  12.0s\n",
            "[CV] dropout_rate=0, learning_rate=0.2 ...............................\n",
            "[CV] .. dropout_rate=0, learning_rate=0.2, score=-2.920, total=  12.2s\n",
            "[CV] dropout_rate=0, learning_rate=0.2 ...............................\n",
            "[CV] .. dropout_rate=0, learning_rate=0.2, score=-0.761, total=  12.1s\n",
            "[CV] dropout_rate=0, learning_rate=0.2 ...............................\n",
            "[CV] .. dropout_rate=0, learning_rate=0.2, score=-2.041, total=  12.3s\n",
            "[CV] dropout_rate=0, learning_rate=0.5 ...............................\n",
            "[CV]  dropout_rate=0, learning_rate=0.5, score=-365.518, total=  12.2s\n",
            "[CV] dropout_rate=0, learning_rate=0.5 ...............................\n",
            "[CV] .. dropout_rate=0, learning_rate=0.5, score=-1.341, total=  11.9s\n",
            "[CV] dropout_rate=0, learning_rate=0.5 ...............................\n",
            "[CV]  dropout_rate=0, learning_rate=0.5, score=-329.263, total=  12.3s\n",
            "[CV] dropout_rate=0, learning_rate=0.5 ...............................\n",
            "[CV] .. dropout_rate=0, learning_rate=0.5, score=-2.788, total=  12.0s\n",
            "[CV] dropout_rate=0, learning_rate=0.5 ...............................\n",
            "[CV]  dropout_rate=0, learning_rate=0.5, score=-265.982, total=  12.2s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.001, score=-18.691, total=  12.1s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.001, score=-12.477, total=  12.1s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.001, score=-35.271, total=  12.2s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.001, score=-6.014, total=  12.3s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.001, score=-5.429, total=  12.3s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.01, score=-6.833, total=  12.1s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.01, score=-5.033, total=  12.2s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.01, score=-9.888, total=  12.4s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.01, score=-2.526, total=  12.3s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.01, score=-7.655, total=  12.2s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.1, score=-15.753, total=  12.1s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.1, score=-7.666, total=  12.2s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.1, score=-18.438, total=  12.2s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.1, score=-8.280, total=  12.3s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.1, score=-27.646, total=  12.3s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.2 .............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.2, score=-14.583, total=  12.4s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.2 .............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.2, score=-9.558, total=  12.1s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.2 .............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.2, score=-33.151, total=  12.1s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.2 .............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.2, score=-24.825, total=  12.4s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.2 .............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.2, score=-24.545, total=  12.3s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.5 .............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.5, score=-154.372, total=  12.1s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.5 .............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.5, score=-123.649, total=  12.1s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.5 .............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.5, score=-323.282, total=  12.1s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.5 .............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.5, score=-99.903, total=  12.0s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.5 .............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.5, score=-84.163, total=  12.3s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.001, score=-57.481, total=  12.2s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.001, score=-39.294, total=  12.3s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.001, score=-34.330, total=  12.1s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.001, score=-34.992, total=  12.1s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.001, score=-36.242, total=  12.5s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.01, score=-9.274, total=  12.2s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.01, score=-3.911, total=  12.3s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.01, score=-29.554, total=  12.1s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.01, score=-17.323, total=  12.2s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.01, score=-10.101, total=  12.2s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.1, score=-118.898, total=  12.2s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.1, score=-14.067, total=  12.2s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.1, score=-58.160, total=  12.3s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.1, score=-56.993, total=  12.2s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.1, score=-36.372, total=  12.2s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.2 .............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.2, score=-70.295, total=  12.7s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.2 .............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.2, score=-51.280, total=  12.0s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.2 .............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.2, score=-101.001, total=  12.1s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.2 .............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.2, score=-78.364, total=  12.1s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.2 .............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.2, score=-51.273, total=  12.1s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.5 .............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.5, score=-128.588, total=  12.3s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.5 .............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.5, score=-128.622, total=  12.2s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.5 .............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.5, score=-140.504, total=  12.2s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.5 .............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.5, score=-236.823, total=  12.2s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.5 .............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.5, score=-139.500, total=  12.2s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed: 15.3min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lz41KwydEo55",
        "outputId": "2380078a-d035-4138-ffcf-77c11822fb6f"
      },
      "source": [
        "# summerize results\n",
        "print('Best:{}, using {}'.format(grid_result.best_score_, grid_result.best_params_))\n",
        "means= grid_result.cv_results_['mean_test_score']\n",
        "stds= grid_result.cv_results_['std_test_score']\n",
        "params= grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best:-0.6202531516551971, using {'dropout_rate': 0, 'learning_rate': 0.001}\n",
            "-0.6202531516551971,0.15041367682159368 with: {'dropout_rate': 0, 'learning_rate': 0.001}\n",
            "-0.8936102747917175,0.4679097411431064 with: {'dropout_rate': 0, 'learning_rate': 0.01}\n",
            "-1.8033161759376526,1.3253189755385835 with: {'dropout_rate': 0, 'learning_rate': 0.1}\n",
            "-1.4099546074867249,0.9257579540998265 with: {'dropout_rate': 0, 'learning_rate': 0.2}\n",
            "-192.97868065834047,159.1038971961304 with: {'dropout_rate': 0, 'learning_rate': 0.5}\n",
            "-15.576375484466553,10.96918756355158 with: {'dropout_rate': 0.1, 'learning_rate': 0.001}\n",
            "-6.387226819992065,2.4819729111856277 with: {'dropout_rate': 0.1, 'learning_rate': 0.01}\n",
            "-15.556726169586181,7.344458574561042 with: {'dropout_rate': 0.1, 'learning_rate': 0.1}\n",
            "-21.332647132873536,8.323171094069938 with: {'dropout_rate': 0.1, 'learning_rate': 0.2}\n",
            "-157.07378082275392,86.41087196050059 with: {'dropout_rate': 0.1, 'learning_rate': 0.5}\n",
            "-40.467848205566405,8.675514369562695 with: {'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
            "-14.032849884033203,8.857740812286439 with: {'dropout_rate': 0.2, 'learning_rate': 0.01}\n",
            "-56.89772472381592,34.93272465252846 with: {'dropout_rate': 0.2, 'learning_rate': 0.1}\n",
            "-70.44253082275391,18.60759318661595 with: {'dropout_rate': 0.2, 'learning_rate': 0.2}\n",
            "-154.807470703125,41.32447004750781 with: {'dropout_rate': 0.2, 'learning_rate': 0.5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PjUnvMeEuHr",
        "outputId": "1c727892-9d09-4a48-b935-a00bb68c0c5f"
      },
      "source": [
        "# Tuning hyperparameters: Activation function and Kernal intitilizer\n",
        "def create_model_af_ker_ini(activation_function,init):\n",
        "  model= Sequential()\n",
        "  model.add(Dense(10, input_dim=10, kernel_initializer= init, activation=activation_function))\n",
        "  model.add(Dropout(0))\n",
        "  model.add(Dense(8, kernel_initializer= init, activation=activation_function))\n",
        "  model.add(Dropout(0))\n",
        "  model.add(Dense(8, kernel_initializer= init, activation=activation_function))\n",
        "  model.add(Dropout(0))\n",
        "  model.add(Dense(1, kernel_initializer= init, activation='linear')) \n",
        "  adam= Adam(learning_rate= 0.001)\n",
        "# Compile model\n",
        "  model.compile(loss='mean_squared_error', optimizer=adam)\n",
        "  return model\n",
        "\n",
        "# Define regression model\n",
        "model= KerasRegressor(build_fn=create_model_af_ker_ini, verbose=0, batch_size=100, epochs=100)\n",
        "# Define grid search model\n",
        "activation_function=['linear', 'relu']\n",
        "init=['uniform', 'normal', 'zero']\n",
        "# Make a dictionary of grid search parameters\n",
        "param_grid= dict(activation_function= activation_function, init=init)\n",
        "#build and fit the gridsearchCV\n",
        "grid= GridSearchCV(estimator=model, param_grid=param_grid, cv= KFold(), verbose=10 )\n",
        "grid_result= grid.fit(x_standerdized,y)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "[CV] activation_function=linear, init=uniform ........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=linear, init=uniform, score=-0.921, total=  12.1s\n",
            "[CV] activation_function=linear, init=uniform ........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=linear, init=uniform, score=-0.583, total=  12.1s\n",
            "[CV] activation_function=linear, init=uniform ........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   24.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=linear, init=uniform, score=-0.751, total=  12.0s\n",
            "[CV] activation_function=linear, init=uniform ........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   36.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=linear, init=uniform, score=-0.553, total=  12.2s\n",
            "[CV] activation_function=linear, init=uniform ........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   48.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=linear, init=uniform, score=-0.897, total=  11.9s\n",
            "[CV] activation_function=linear, init=normal .........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.0min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=linear, init=normal, score=-0.775, total=  12.1s\n",
            "[CV] activation_function=linear, init=normal .........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.2min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=linear, init=normal, score=-0.444, total=  12.0s\n",
            "[CV] activation_function=linear, init=normal .........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  1.4min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=linear, init=normal, score=-0.578, total=  12.1s\n",
            "[CV] activation_function=linear, init=normal .........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  1.6min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=linear, init=normal, score=-0.458, total=  11.9s\n",
            "[CV] activation_function=linear, init=normal .........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.8min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=linear, init=normal, score=-0.579, total=  12.1s\n",
            "[CV] activation_function=linear, init=zero ...........................\n",
            "[CV]  activation_function=linear, init=zero, score=-15681.720, total=  12.6s\n",
            "[CV] activation_function=linear, init=zero ...........................\n",
            "[CV]  activation_function=linear, init=zero, score=-13996.413, total=  12.1s\n",
            "[CV] activation_function=linear, init=zero ...........................\n",
            "[CV]  activation_function=linear, init=zero, score=-16285.176, total=  12.0s\n",
            "[CV] activation_function=linear, init=zero ...........................\n",
            "[CV]  activation_function=linear, init=zero, score=-15403.919, total=  12.1s\n",
            "[CV] activation_function=linear, init=zero ...........................\n",
            "[CV]  activation_function=linear, init=zero, score=-14512.598, total=  12.2s\n",
            "[CV] activation_function=relu, init=uniform ..........................\n",
            "[CV]  activation_function=relu, init=uniform, score=-0.696, total=  12.0s\n",
            "[CV] activation_function=relu, init=uniform ..........................\n",
            "[CV]  activation_function=relu, init=uniform, score=-0.494, total=  12.2s\n",
            "[CV] activation_function=relu, init=uniform ..........................\n",
            "[CV]  activation_function=relu, init=uniform, score=-0.909, total=  12.1s\n",
            "[CV] activation_function=relu, init=uniform ..........................\n",
            "[CV]  activation_function=relu, init=uniform, score=-0.629, total=  12.2s\n",
            "[CV] activation_function=relu, init=uniform ..........................\n",
            "[CV]  activation_function=relu, init=uniform, score=-1.490, total=  12.2s\n",
            "[CV] activation_function=relu, init=normal ...........................\n",
            "[CV]  activation_function=relu, init=normal, score=-0.819, total=  12.0s\n",
            "[CV] activation_function=relu, init=normal ...........................\n",
            "[CV]  activation_function=relu, init=normal, score=-0.528, total=  12.1s\n",
            "[CV] activation_function=relu, init=normal ...........................\n",
            "[CV]  activation_function=relu, init=normal, score=-0.988, total=  12.6s\n",
            "[CV] activation_function=relu, init=normal ...........................\n",
            "[CV]  activation_function=relu, init=normal, score=-0.434, total=  12.2s\n",
            "[CV] activation_function=relu, init=normal ...........................\n",
            "[CV]  activation_function=relu, init=normal, score=-0.879, total=  12.1s\n",
            "[CV] activation_function=relu, init=zero .............................\n",
            "[CV]  activation_function=relu, init=zero, score=-15681.694, total=  12.2s\n",
            "[CV] activation_function=relu, init=zero .............................\n",
            "[CV]  activation_function=relu, init=zero, score=-13996.419, total=  12.1s\n",
            "[CV] activation_function=relu, init=zero .............................\n",
            "[CV]  activation_function=relu, init=zero, score=-16285.111, total=  12.2s\n",
            "[CV] activation_function=relu, init=zero .............................\n",
            "[CV]  activation_function=relu, init=zero, score=-15403.912, total=  12.2s\n",
            "[CV] activation_function=relu, init=zero .............................\n",
            "[CV]  activation_function=relu, init=zero, score=-14512.562, total=  12.1s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  6.1min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgWT7TVtNDpl",
        "outputId": "3fcb031b-b1ce-474c-e735-412c0a018f72"
      },
      "source": [
        "# summerize results\n",
        "print('Best:{}, using {}'.format(grid_result.best_score_, grid_result.best_params_))\n",
        "means= grid_result.cv_results_['mean_test_score']\n",
        "stds= grid_result.cv_results_['std_test_score']\n",
        "params= grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best:-0.5668147683143616, using {'activation_function': 'linear', 'init': 'normal'}\n",
            "-0.7411278247833252,0.15301058356273062 with: {'activation_function': 'linear', 'init': 'uniform'}\n",
            "-0.5668147683143616,0.11879992028700706 with: {'activation_function': 'linear', 'init': 'normal'}\n",
            "-15175.9650390625,820.9139239393505 with: {'activation_function': 'linear', 'init': 'zero'}\n",
            "-0.8436641454696655,0.3496725835345604 with: {'activation_function': 'relu', 'init': 'uniform'}\n",
            "-0.7295901656150818,0.2119623338575594 with: {'activation_function': 'relu', 'init': 'normal'}\n",
            "-15175.9396484375,820.8971540605952 with: {'activation_function': 'relu', 'init': 'zero'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkSlZhZWNLEq",
        "outputId": "16fc0b98-1070-4444-fb34-7289b0164ef7"
      },
      "source": [
        "# Tuning parameter: Number of neurons in activation layer\n",
        "def create_model_neuron(neuron1,neuron2, neuron3):\n",
        "  model= Sequential()\n",
        "  model.add(Dense(neuron1, input_dim=10, kernel_initializer= 'normal', activation='linear'))\n",
        "  model.add(Dropout(0))\n",
        "  model.add(Dense(neuron2, kernel_initializer= 'normal', activation='linear'))\n",
        "  model.add(Dropout(0))\n",
        "  model.add(Dense(neuron3, kernel_initializer= 'normal', activation='linear'))\n",
        "  model.add(Dropout(0))\n",
        "  model.add(Dense(1, kernel_initializer= 'normal', activation='linear')) \n",
        "  adam= Adam(learning_rate= 0.001)\n",
        "# Compile model\n",
        "  model.compile(loss='mean_squared_error', optimizer=adam)\n",
        "  return model\n",
        "\n",
        "# Define regression model\n",
        "model= KerasRegressor(build_fn=create_model_neuron, verbose=0, batch_size=100, epochs=100)\n",
        "# Define grid search model\n",
        "neuron1=[4,8,16]\n",
        "neuron2=[4,8,16]\n",
        "neuron3=[4,8,16]\n",
        "# Make a dictionary of grid search parameters\n",
        "param_grid= dict(neuron1= neuron1, neuron2=neuron2,neuron3=neuron3 )\n",
        "#build and fit the gridsearchCV\n",
        "grid= GridSearchCV(estimator=model, param_grid=param_grid, cv= KFold(), verbose=10 )\n",
        "grid_result= grid.fit(x_standerdized,y)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
            "[CV] neuron1=4, neuron2=4, neuron3=4 .................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... neuron1=4, neuron2=4, neuron3=4, score=-0.825, total=  10.6s\n",
            "[CV] neuron1=4, neuron2=4, neuron3=4 .................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... neuron1=4, neuron2=4, neuron3=4, score=-0.569, total=  10.8s\n",
            "[CV] neuron1=4, neuron2=4, neuron3=4 .................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   21.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... neuron1=4, neuron2=4, neuron3=4, score=-0.723, total=  10.6s\n",
            "[CV] neuron1=4, neuron2=4, neuron3=4 .................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   31.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... neuron1=4, neuron2=4, neuron3=4, score=-0.743, total=  10.3s\n",
            "[CV] neuron1=4, neuron2=4, neuron3=4 .................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   42.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... neuron1=4, neuron2=4, neuron3=4, score=-0.751, total=  10.7s\n",
            "[CV] neuron1=4, neuron2=4, neuron3=8 .................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   52.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... neuron1=4, neuron2=4, neuron3=8, score=-0.719, total=  10.6s\n",
            "[CV] neuron1=4, neuron2=4, neuron3=8 .................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.1min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... neuron1=4, neuron2=4, neuron3=8, score=-0.445, total=  10.5s\n",
            "[CV] neuron1=4, neuron2=4, neuron3=8 .................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  1.2min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... neuron1=4, neuron2=4, neuron3=8, score=-0.612, total=  10.6s\n",
            "[CV] neuron1=4, neuron2=4, neuron3=8 .................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  1.4min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... neuron1=4, neuron2=4, neuron3=8, score=-0.622, total=  10.4s\n",
            "[CV] neuron1=4, neuron2=4, neuron3=8 .................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.6min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] .... neuron1=4, neuron2=4, neuron3=8, score=-0.630, total=  10.5s\n",
            "[CV] neuron1=4, neuron2=4, neuron3=16 ................................\n",
            "[CV] ... neuron1=4, neuron2=4, neuron3=16, score=-1.007, total=  11.0s\n",
            "[CV] neuron1=4, neuron2=4, neuron3=16 ................................\n",
            "[CV] ... neuron1=4, neuron2=4, neuron3=16, score=-0.564, total=  10.8s\n",
            "[CV] neuron1=4, neuron2=4, neuron3=16 ................................\n",
            "[CV] ... neuron1=4, neuron2=4, neuron3=16, score=-0.810, total=  10.6s\n",
            "[CV] neuron1=4, neuron2=4, neuron3=16 ................................\n",
            "[CV] ... neuron1=4, neuron2=4, neuron3=16, score=-0.569, total=  10.9s\n",
            "[CV] neuron1=4, neuron2=4, neuron3=16 ................................\n",
            "[CV] ... neuron1=4, neuron2=4, neuron3=16, score=-0.629, total=  11.0s\n",
            "[CV] neuron1=4, neuron2=8, neuron3=4 .................................\n",
            "[CV] .... neuron1=4, neuron2=8, neuron3=4, score=-0.930, total=  10.6s\n",
            "[CV] neuron1=4, neuron2=8, neuron3=4 .................................\n",
            "[CV] .... neuron1=4, neuron2=8, neuron3=4, score=-0.519, total=  10.5s\n",
            "[CV] neuron1=4, neuron2=8, neuron3=4 .................................\n",
            "[CV] .... neuron1=4, neuron2=8, neuron3=4, score=-0.746, total=  10.6s\n",
            "[CV] neuron1=4, neuron2=8, neuron3=4 .................................\n",
            "[CV] .... neuron1=4, neuron2=8, neuron3=4, score=-0.727, total=  10.5s\n",
            "[CV] neuron1=4, neuron2=8, neuron3=4 .................................\n",
            "[CV] .... neuron1=4, neuron2=8, neuron3=4, score=-0.510, total=  10.7s\n",
            "[CV] neuron1=4, neuron2=8, neuron3=8 .................................\n",
            "[CV] .... neuron1=4, neuron2=8, neuron3=8, score=-0.939, total=  10.6s\n",
            "[CV] neuron1=4, neuron2=8, neuron3=8 .................................\n",
            "[CV] .... neuron1=4, neuron2=8, neuron3=8, score=-0.505, total=  10.7s\n",
            "[CV] neuron1=4, neuron2=8, neuron3=8 .................................\n",
            "[CV] .... neuron1=4, neuron2=8, neuron3=8, score=-0.744, total=  10.7s\n",
            "[CV] neuron1=4, neuron2=8, neuron3=8 .................................\n",
            "[CV] .... neuron1=4, neuron2=8, neuron3=8, score=-0.541, total=  10.7s\n",
            "[CV] neuron1=4, neuron2=8, neuron3=8 .................................\n",
            "[CV] .... neuron1=4, neuron2=8, neuron3=8, score=-0.737, total=  10.5s\n",
            "[CV] neuron1=4, neuron2=8, neuron3=16 ................................\n",
            "[CV] ... neuron1=4, neuron2=8, neuron3=16, score=-0.962, total=  11.2s\n",
            "[CV] neuron1=4, neuron2=8, neuron3=16 ................................\n",
            "[CV] ... neuron1=4, neuron2=8, neuron3=16, score=-0.463, total=  10.8s\n",
            "[CV] neuron1=4, neuron2=8, neuron3=16 ................................\n",
            "[CV] ... neuron1=4, neuron2=8, neuron3=16, score=-0.634, total=  10.8s\n",
            "[CV] neuron1=4, neuron2=8, neuron3=16 ................................\n",
            "[CV] ... neuron1=4, neuron2=8, neuron3=16, score=-0.456, total=  10.8s\n",
            "[CV] neuron1=4, neuron2=8, neuron3=16 ................................\n",
            "[CV] ... neuron1=4, neuron2=8, neuron3=16, score=-0.528, total=  10.7s\n",
            "[CV] neuron1=4, neuron2=16, neuron3=4 ................................\n",
            "[CV] ... neuron1=4, neuron2=16, neuron3=4, score=-0.865, total=  10.7s\n",
            "[CV] neuron1=4, neuron2=16, neuron3=4 ................................\n",
            "[CV] ... neuron1=4, neuron2=16, neuron3=4, score=-0.595, total=  10.8s\n",
            "[CV] neuron1=4, neuron2=16, neuron3=4 ................................\n",
            "[CV] ... neuron1=4, neuron2=16, neuron3=4, score=-0.651, total=  10.8s\n",
            "[CV] neuron1=4, neuron2=16, neuron3=4 ................................\n",
            "[CV] ... neuron1=4, neuron2=16, neuron3=4, score=-0.465, total=  10.9s\n",
            "[CV] neuron1=4, neuron2=16, neuron3=4 ................................\n",
            "[CV] ... neuron1=4, neuron2=16, neuron3=4, score=-0.598, total=  10.7s\n",
            "[CV] neuron1=4, neuron2=16, neuron3=8 ................................\n",
            "[CV] ... neuron1=4, neuron2=16, neuron3=8, score=-0.731, total=  11.0s\n",
            "[CV] neuron1=4, neuron2=16, neuron3=8 ................................\n",
            "[CV] ... neuron1=4, neuron2=16, neuron3=8, score=-0.513, total=  11.1s\n",
            "[CV] neuron1=4, neuron2=16, neuron3=8 ................................\n",
            "[CV] ... neuron1=4, neuron2=16, neuron3=8, score=-0.667, total=  10.7s\n",
            "[CV] neuron1=4, neuron2=16, neuron3=8 ................................\n",
            "[CV] ... neuron1=4, neuron2=16, neuron3=8, score=-0.406, total=  10.9s\n",
            "[CV] neuron1=4, neuron2=16, neuron3=8 ................................\n",
            "[CV] ... neuron1=4, neuron2=16, neuron3=8, score=-0.641, total=  10.7s\n",
            "[CV] neuron1=4, neuron2=16, neuron3=16 ...............................\n",
            "[CV] .. neuron1=4, neuron2=16, neuron3=16, score=-1.179, total=  11.0s\n",
            "[CV] neuron1=4, neuron2=16, neuron3=16 ...............................\n",
            "[CV] .. neuron1=4, neuron2=16, neuron3=16, score=-0.471, total=  10.8s\n",
            "[CV] neuron1=4, neuron2=16, neuron3=16 ...............................\n",
            "[CV] .. neuron1=4, neuron2=16, neuron3=16, score=-0.774, total=  11.2s\n",
            "[CV] neuron1=4, neuron2=16, neuron3=16 ...............................\n",
            "[CV] .. neuron1=4, neuron2=16, neuron3=16, score=-0.558, total=  11.2s\n",
            "[CV] neuron1=4, neuron2=16, neuron3=16 ...............................\n",
            "[CV] .. neuron1=4, neuron2=16, neuron3=16, score=-0.558, total=  10.9s\n",
            "[CV] neuron1=8, neuron2=4, neuron3=4 .................................\n",
            "[CV] .... neuron1=8, neuron2=4, neuron3=4, score=-1.402, total=  10.5s\n",
            "[CV] neuron1=8, neuron2=4, neuron3=4 .................................\n",
            "[CV] .... neuron1=8, neuron2=4, neuron3=4, score=-0.502, total=  10.6s\n",
            "[CV] neuron1=8, neuron2=4, neuron3=4 .................................\n",
            "[CV] .... neuron1=8, neuron2=4, neuron3=4, score=-0.871, total=  10.8s\n",
            "[CV] neuron1=8, neuron2=4, neuron3=4 .................................\n",
            "[CV] .... neuron1=8, neuron2=4, neuron3=4, score=-0.504, total=  10.6s\n",
            "[CV] neuron1=8, neuron2=4, neuron3=4 .................................\n",
            "[CV] .... neuron1=8, neuron2=4, neuron3=4, score=-0.734, total=  10.5s\n",
            "[CV] neuron1=8, neuron2=4, neuron3=8 .................................\n",
            "[CV] .... neuron1=8, neuron2=4, neuron3=8, score=-1.146, total=  10.7s\n",
            "[CV] neuron1=8, neuron2=4, neuron3=8 .................................\n",
            "[CV] .... neuron1=8, neuron2=4, neuron3=8, score=-0.448, total=  10.7s\n",
            "[CV] neuron1=8, neuron2=4, neuron3=8 .................................\n",
            "[CV] .... neuron1=8, neuron2=4, neuron3=8, score=-0.740, total=  10.6s\n",
            "[CV] neuron1=8, neuron2=4, neuron3=8 .................................\n",
            "[CV] .... neuron1=8, neuron2=4, neuron3=8, score=-0.460, total=  10.5s\n",
            "[CV] neuron1=8, neuron2=4, neuron3=8 .................................\n",
            "[CV] .... neuron1=8, neuron2=4, neuron3=8, score=-0.597, total=  10.6s\n",
            "[CV] neuron1=8, neuron2=4, neuron3=16 ................................\n",
            "[CV] ... neuron1=8, neuron2=4, neuron3=16, score=-1.277, total=  10.9s\n",
            "[CV] neuron1=8, neuron2=4, neuron3=16 ................................\n",
            "[CV] ... neuron1=8, neuron2=4, neuron3=16, score=-0.696, total=  10.7s\n",
            "[CV] neuron1=8, neuron2=4, neuron3=16 ................................\n",
            "[CV] ... neuron1=8, neuron2=4, neuron3=16, score=-0.768, total=  10.9s\n",
            "[CV] neuron1=8, neuron2=4, neuron3=16 ................................\n",
            "[CV] ... neuron1=8, neuron2=4, neuron3=16, score=-0.523, total=  11.4s\n",
            "[CV] neuron1=8, neuron2=4, neuron3=16 ................................\n",
            "[CV] ... neuron1=8, neuron2=4, neuron3=16, score=-0.671, total=  10.7s\n",
            "[CV] neuron1=8, neuron2=8, neuron3=4 .................................\n",
            "[CV] .... neuron1=8, neuron2=8, neuron3=4, score=-1.091, total=  10.6s\n",
            "[CV] neuron1=8, neuron2=8, neuron3=4 .................................\n",
            "[CV] .... neuron1=8, neuron2=8, neuron3=4, score=-0.552, total=  10.6s\n",
            "[CV] neuron1=8, neuron2=8, neuron3=4 .................................\n",
            "[CV] .... neuron1=8, neuron2=8, neuron3=4, score=-0.645, total=  10.6s\n",
            "[CV] neuron1=8, neuron2=8, neuron3=4 .................................\n",
            "[CV] .... neuron1=8, neuron2=8, neuron3=4, score=-0.507, total=  10.5s\n",
            "[CV] neuron1=8, neuron2=8, neuron3=4 .................................\n",
            "[CV] .... neuron1=8, neuron2=8, neuron3=4, score=-0.548, total=  10.5s\n",
            "[CV] neuron1=8, neuron2=8, neuron3=8 .................................\n",
            "[CV] .... neuron1=8, neuron2=8, neuron3=8, score=-1.037, total=  10.7s\n",
            "[CV] neuron1=8, neuron2=8, neuron3=8 .................................\n",
            "[CV] .... neuron1=8, neuron2=8, neuron3=8, score=-0.408, total=  10.7s\n",
            "[CV] neuron1=8, neuron2=8, neuron3=8 .................................\n",
            "[CV] .... neuron1=8, neuron2=8, neuron3=8, score=-0.719, total=  10.8s\n",
            "[CV] neuron1=8, neuron2=8, neuron3=8 .................................\n",
            "[CV] .... neuron1=8, neuron2=8, neuron3=8, score=-0.566, total=  10.6s\n",
            "[CV] neuron1=8, neuron2=8, neuron3=8 .................................\n",
            "[CV] .... neuron1=8, neuron2=8, neuron3=8, score=-0.530, total=  11.1s\n",
            "[CV] neuron1=8, neuron2=8, neuron3=16 ................................\n",
            "[CV] ... neuron1=8, neuron2=8, neuron3=16, score=-1.243, total=  10.7s\n",
            "[CV] neuron1=8, neuron2=8, neuron3=16 ................................\n",
            "[CV] ... neuron1=8, neuron2=8, neuron3=16, score=-0.614, total=  10.9s\n",
            "[CV] neuron1=8, neuron2=8, neuron3=16 ................................\n",
            "[CV] ... neuron1=8, neuron2=8, neuron3=16, score=-0.926, total=  11.3s\n",
            "[CV] neuron1=8, neuron2=8, neuron3=16 ................................\n",
            "[CV] ... neuron1=8, neuron2=8, neuron3=16, score=-0.445, total=  11.1s\n",
            "[CV] neuron1=8, neuron2=8, neuron3=16 ................................\n",
            "[CV] ... neuron1=8, neuron2=8, neuron3=16, score=-0.514, total=  10.8s\n",
            "[CV] neuron1=8, neuron2=16, neuron3=4 ................................\n",
            "[CV] ... neuron1=8, neuron2=16, neuron3=4, score=-0.852, total=  10.9s\n",
            "[CV] neuron1=8, neuron2=16, neuron3=4 ................................\n",
            "[CV] ... neuron1=8, neuron2=16, neuron3=4, score=-0.483, total=  10.9s\n",
            "[CV] neuron1=8, neuron2=16, neuron3=4 ................................\n",
            "[CV] ... neuron1=8, neuron2=16, neuron3=4, score=-0.714, total=  10.9s\n",
            "[CV] neuron1=8, neuron2=16, neuron3=4 ................................\n",
            "[CV] ... neuron1=8, neuron2=16, neuron3=4, score=-0.490, total=  10.9s\n",
            "[CV] neuron1=8, neuron2=16, neuron3=4 ................................\n",
            "[CV] ... neuron1=8, neuron2=16, neuron3=4, score=-0.607, total=  10.9s\n",
            "[CV] neuron1=8, neuron2=16, neuron3=8 ................................\n",
            "[CV] ... neuron1=8, neuron2=16, neuron3=8, score=-1.028, total=  11.1s\n",
            "[CV] neuron1=8, neuron2=16, neuron3=8 ................................\n",
            "[CV] ... neuron1=8, neuron2=16, neuron3=8, score=-0.653, total=  11.1s\n",
            "[CV] neuron1=8, neuron2=16, neuron3=8 ................................\n",
            "[CV] ... neuron1=8, neuron2=16, neuron3=8, score=-0.696, total=  10.9s\n",
            "[CV] neuron1=8, neuron2=16, neuron3=8 ................................\n",
            "[CV] ... neuron1=8, neuron2=16, neuron3=8, score=-0.444, total=  10.9s\n",
            "[CV] neuron1=8, neuron2=16, neuron3=8 ................................\n",
            "[CV] ... neuron1=8, neuron2=16, neuron3=8, score=-0.728, total=  11.0s\n",
            "[CV] neuron1=8, neuron2=16, neuron3=16 ...............................\n",
            "[CV] .. neuron1=8, neuron2=16, neuron3=16, score=-0.891, total=  11.0s\n",
            "[CV] neuron1=8, neuron2=16, neuron3=16 ...............................\n",
            "[CV] .. neuron1=8, neuron2=16, neuron3=16, score=-0.451, total=  11.0s\n",
            "[CV] neuron1=8, neuron2=16, neuron3=16 ...............................\n",
            "[CV] .. neuron1=8, neuron2=16, neuron3=16, score=-0.718, total=  11.1s\n",
            "[CV] neuron1=8, neuron2=16, neuron3=16 ...............................\n",
            "[CV] .. neuron1=8, neuron2=16, neuron3=16, score=-0.573, total=  11.1s\n",
            "[CV] neuron1=8, neuron2=16, neuron3=16 ...............................\n",
            "[CV] .. neuron1=8, neuron2=16, neuron3=16, score=-0.672, total=  11.0s\n",
            "[CV] neuron1=16, neuron2=4, neuron3=4 ................................\n",
            "[CV] ... neuron1=16, neuron2=4, neuron3=4, score=-0.756, total=  10.6s\n",
            "[CV] neuron1=16, neuron2=4, neuron3=4 ................................\n",
            "[CV] ... neuron1=16, neuron2=4, neuron3=4, score=-0.432, total=  10.9s\n",
            "[CV] neuron1=16, neuron2=4, neuron3=4 ................................\n",
            "[CV] ... neuron1=16, neuron2=4, neuron3=4, score=-0.808, total=  10.6s\n",
            "[CV] neuron1=16, neuron2=4, neuron3=4 ................................\n",
            "[CV] ... neuron1=16, neuron2=4, neuron3=4, score=-0.524, total=  10.7s\n",
            "[CV] neuron1=16, neuron2=4, neuron3=4 ................................\n",
            "[CV] ... neuron1=16, neuron2=4, neuron3=4, score=-0.619, total=  10.8s\n",
            "[CV] neuron1=16, neuron2=4, neuron3=8 ................................\n",
            "[CV] ... neuron1=16, neuron2=4, neuron3=8, score=-0.833, total=  10.8s\n",
            "[CV] neuron1=16, neuron2=4, neuron3=8 ................................\n",
            "[CV] ... neuron1=16, neuron2=4, neuron3=8, score=-0.863, total=  10.7s\n",
            "[CV] neuron1=16, neuron2=4, neuron3=8 ................................\n",
            "[CV] ... neuron1=16, neuron2=4, neuron3=8, score=-0.926, total=  10.6s\n",
            "[CV] neuron1=16, neuron2=4, neuron3=8 ................................\n",
            "[CV] ... neuron1=16, neuron2=4, neuron3=8, score=-0.605, total=  10.6s\n",
            "[CV] neuron1=16, neuron2=4, neuron3=8 ................................\n",
            "[CV] ... neuron1=16, neuron2=4, neuron3=8, score=-0.704, total=  10.7s\n",
            "[CV] neuron1=16, neuron2=4, neuron3=16 ...............................\n",
            "[CV] .. neuron1=16, neuron2=4, neuron3=16, score=-0.752, total=  11.1s\n",
            "[CV] neuron1=16, neuron2=4, neuron3=16 ...............................\n",
            "[CV] .. neuron1=16, neuron2=4, neuron3=16, score=-0.518, total=  11.0s\n",
            "[CV] neuron1=16, neuron2=4, neuron3=16 ...............................\n",
            "[CV] .. neuron1=16, neuron2=4, neuron3=16, score=-0.618, total=  11.3s\n",
            "[CV] neuron1=16, neuron2=4, neuron3=16 ...............................\n",
            "[CV] .. neuron1=16, neuron2=4, neuron3=16, score=-0.536, total=  10.8s\n",
            "[CV] neuron1=16, neuron2=4, neuron3=16 ...............................\n",
            "[CV] .. neuron1=16, neuron2=4, neuron3=16, score=-0.841, total=  10.9s\n",
            "[CV] neuron1=16, neuron2=8, neuron3=4 ................................\n",
            "[CV] ... neuron1=16, neuron2=8, neuron3=4, score=-1.018, total=  10.8s\n",
            "[CV] neuron1=16, neuron2=8, neuron3=4 ................................\n",
            "[CV] ... neuron1=16, neuron2=8, neuron3=4, score=-0.420, total=  10.8s\n",
            "[CV] neuron1=16, neuron2=8, neuron3=4 ................................\n",
            "[CV] ... neuron1=16, neuron2=8, neuron3=4, score=-0.687, total=  10.7s\n",
            "[CV] neuron1=16, neuron2=8, neuron3=4 ................................\n",
            "[CV] ... neuron1=16, neuron2=8, neuron3=4, score=-0.544, total=  10.7s\n",
            "[CV] neuron1=16, neuron2=8, neuron3=4 ................................\n",
            "[CV] ... neuron1=16, neuron2=8, neuron3=4, score=-0.658, total=  10.7s\n",
            "[CV] neuron1=16, neuron2=8, neuron3=8 ................................\n",
            "[CV] ... neuron1=16, neuron2=8, neuron3=8, score=-0.612, total=  10.9s\n",
            "[CV] neuron1=16, neuron2=8, neuron3=8 ................................\n",
            "[CV] ... neuron1=16, neuron2=8, neuron3=8, score=-0.419, total=  10.8s\n",
            "[CV] neuron1=16, neuron2=8, neuron3=8 ................................\n",
            "[CV] ... neuron1=16, neuron2=8, neuron3=8, score=-0.597, total=  10.8s\n",
            "[CV] neuron1=16, neuron2=8, neuron3=8 ................................\n",
            "[CV] ... neuron1=16, neuron2=8, neuron3=8, score=-0.634, total=  11.2s\n",
            "[CV] neuron1=16, neuron2=8, neuron3=8 ................................\n",
            "[CV] ... neuron1=16, neuron2=8, neuron3=8, score=-0.641, total=  10.8s\n",
            "[CV] neuron1=16, neuron2=8, neuron3=16 ...............................\n",
            "[CV] .. neuron1=16, neuron2=8, neuron3=16, score=-0.957, total=  10.8s\n",
            "[CV] neuron1=16, neuron2=8, neuron3=16 ...............................\n",
            "[CV] .. neuron1=16, neuron2=8, neuron3=16, score=-0.502, total=  11.1s\n",
            "[CV] neuron1=16, neuron2=8, neuron3=16 ...............................\n",
            "[CV] .. neuron1=16, neuron2=8, neuron3=16, score=-0.607, total=  11.1s\n",
            "[CV] neuron1=16, neuron2=8, neuron3=16 ...............................\n",
            "[CV] .. neuron1=16, neuron2=8, neuron3=16, score=-0.564, total=  11.0s\n",
            "[CV] neuron1=16, neuron2=8, neuron3=16 ...............................\n",
            "[CV] .. neuron1=16, neuron2=8, neuron3=16, score=-0.813, total=  11.0s\n",
            "[CV] neuron1=16, neuron2=16, neuron3=4 ...............................\n",
            "[CV] .. neuron1=16, neuron2=16, neuron3=4, score=-0.832, total=  10.9s\n",
            "[CV] neuron1=16, neuron2=16, neuron3=4 ...............................\n",
            "[CV] .. neuron1=16, neuron2=16, neuron3=4, score=-0.392, total=  11.0s\n",
            "[CV] neuron1=16, neuron2=16, neuron3=4 ...............................\n",
            "[CV] .. neuron1=16, neuron2=16, neuron3=4, score=-0.894, total=  10.9s\n",
            "[CV] neuron1=16, neuron2=16, neuron3=4 ...............................\n",
            "[CV] .. neuron1=16, neuron2=16, neuron3=4, score=-0.476, total=  11.1s\n",
            "[CV] neuron1=16, neuron2=16, neuron3=4 ...............................\n",
            "[CV] .. neuron1=16, neuron2=16, neuron3=4, score=-0.711, total=  10.9s\n",
            "[CV] neuron1=16, neuron2=16, neuron3=8 ...............................\n",
            "[CV] .. neuron1=16, neuron2=16, neuron3=8, score=-0.788, total=  11.3s\n",
            "[CV] neuron1=16, neuron2=16, neuron3=8 ...............................\n",
            "[CV] .. neuron1=16, neuron2=16, neuron3=8, score=-0.487, total=  10.9s\n",
            "[CV] neuron1=16, neuron2=16, neuron3=8 ...............................\n",
            "[CV] .. neuron1=16, neuron2=16, neuron3=8, score=-0.656, total=  11.0s\n",
            "[CV] neuron1=16, neuron2=16, neuron3=8 ...............................\n",
            "[CV] .. neuron1=16, neuron2=16, neuron3=8, score=-0.584, total=  11.0s\n",
            "[CV] neuron1=16, neuron2=16, neuron3=8 ...............................\n",
            "[CV] .. neuron1=16, neuron2=16, neuron3=8, score=-0.574, total=  11.3s\n",
            "[CV] neuron1=16, neuron2=16, neuron3=16 ..............................\n",
            "[CV] . neuron1=16, neuron2=16, neuron3=16, score=-1.084, total=  11.2s\n",
            "[CV] neuron1=16, neuron2=16, neuron3=16 ..............................\n",
            "[CV] . neuron1=16, neuron2=16, neuron3=16, score=-0.844, total=  11.1s\n",
            "[CV] neuron1=16, neuron2=16, neuron3=16 ..............................\n",
            "[CV] . neuron1=16, neuron2=16, neuron3=16, score=-1.035, total=  11.1s\n",
            "[CV] neuron1=16, neuron2=16, neuron3=16 ..............................\n",
            "[CV] . neuron1=16, neuron2=16, neuron3=16, score=-1.069, total=  11.1s\n",
            "[CV] neuron1=16, neuron2=16, neuron3=16 ..............................\n",
            "[CV] . neuron1=16, neuron2=16, neuron3=16, score=-0.738, total=  11.3s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 135 out of 135 | elapsed: 24.4min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmtsXE_Vn4CQ",
        "outputId": "00ec1319-1383-4fa7-9ada-f66f7274c762"
      },
      "source": [
        "# summerize results\n",
        "print('Best:{}, using {}'.format(grid_result.best_score_, grid_result.best_params_))\n",
        "means= grid_result.cv_results_['mean_test_score']\n",
        "stds= grid_result.cv_results_['std_test_score']\n",
        "params= grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best:-0.5807726323604584, using {'neuron1': 16, 'neuron2': 8, 'neuron3': 8}\n",
            "-0.7220181941986084,0.08416009438280064 with: {'neuron1': 4, 'neuron2': 4, 'neuron3': 4}\n",
            "-0.6055780589580536,0.08882005933215655 with: {'neuron1': 4, 'neuron2': 4, 'neuron3': 8}\n",
            "-0.7158999562263488,0.17093397176417297 with: {'neuron1': 4, 'neuron2': 4, 'neuron3': 16}\n",
            "-0.6861926317214966,0.15740018839082623 with: {'neuron1': 4, 'neuron2': 8, 'neuron3': 4}\n",
            "-0.6932720303535461,0.15690995162133586 with: {'neuron1': 4, 'neuron2': 8, 'neuron3': 8}\n",
            "-0.6085978329181672,0.18775503341572802 with: {'neuron1': 4, 'neuron2': 8, 'neuron3': 16}\n",
            "-0.6348135054111481,0.13044997059738617 with: {'neuron1': 4, 'neuron2': 16, 'neuron3': 4}\n",
            "-0.5916290521621704,0.11655942939436241 with: {'neuron1': 4, 'neuron2': 16, 'neuron3': 8}\n",
            "-0.7080458760261535,0.256148103591311 with: {'neuron1': 4, 'neuron2': 16, 'neuron3': 16}\n",
            "-0.802600872516632,0.33088811859958867 with: {'neuron1': 8, 'neuron2': 4, 'neuron3': 4}\n",
            "-0.6781694948673248,0.25701531245012094 with: {'neuron1': 8, 'neuron2': 4, 'neuron3': 8}\n",
            "-0.7870041728019714,0.25768193930127015 with: {'neuron1': 8, 'neuron2': 4, 'neuron3': 16}\n",
            "-0.6687316179275513,0.21602025719806375 with: {'neuron1': 8, 'neuron2': 8, 'neuron3': 4}\n",
            "-0.652083945274353,0.21642284050544924 with: {'neuron1': 8, 'neuron2': 8, 'neuron3': 8}\n",
            "-0.7482272386550903,0.2968572261179588 with: {'neuron1': 8, 'neuron2': 8, 'neuron3': 16}\n",
            "-0.6291580021381378,0.1398899807968355 with: {'neuron1': 8, 'neuron2': 16, 'neuron3': 4}\n",
            "-0.7097985506057739,0.1875036647068518 with: {'neuron1': 8, 'neuron2': 16, 'neuron3': 8}\n",
            "-0.6608809471130371,0.1472684241549915 with: {'neuron1': 8, 'neuron2': 16, 'neuron3': 16}\n",
            "-0.627804833650589,0.1399729090218215 with: {'neuron1': 16, 'neuron2': 4, 'neuron3': 4}\n",
            "-0.7862915754318237,0.11603289222826747 with: {'neuron1': 16, 'neuron2': 4, 'neuron3': 8}\n",
            "-0.6531635999679566,0.1250613046754254 with: {'neuron1': 16, 'neuron2': 4, 'neuron3': 16}\n",
            "-0.6653517782688141,0.19978812813492988 with: {'neuron1': 16, 'neuron2': 8, 'neuron3': 4}\n",
            "-0.5807726323604584,0.08261169893618497 with: {'neuron1': 16, 'neuron2': 8, 'neuron3': 8}\n",
            "-0.6885806560516358,0.16990197965852263 with: {'neuron1': 16, 'neuron2': 8, 'neuron3': 16}\n",
            "-0.661070054769516,0.196212725415476 with: {'neuron1': 16, 'neuron2': 16, 'neuron3': 4}\n",
            "-0.6175372898578644,0.10068543223421779 with: {'neuron1': 16, 'neuron2': 16, 'neuron3': 8}\n",
            "-0.9540107607841491,0.13812824644790833 with: {'neuron1': 16, 'neuron2': 16, 'neuron3': 16}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFNPTe6jn7te",
        "outputId": "0c56468a-ab83-4a29-8850-8108f22d11c8"
      },
      "source": [
        "# model using optimum hyperparameters\n",
        "# Tuning parameter: Number of neurons in activation layer\n",
        "def create_model_opt():\n",
        "  model= Sequential()\n",
        "  model.add(Dense(16, input_dim=10, kernel_initializer= 'normal', activation='linear'))\n",
        "  model.add(Dropout(0))\n",
        "  model.add(Dense(8, kernel_initializer= 'normal', activation='linear'))\n",
        "  model.add(Dropout(0))\n",
        "  model.add(Dense(8, kernel_initializer= 'normal', activation='linear'))\n",
        "  model.add(Dropout(0))\n",
        "  model.add(Dense(1, kernel_initializer= 'normal', activation='linear')) \n",
        "  adam= Adam(learning_rate= 0.001)\n",
        "# Compile model\n",
        "  model.compile(loss='mean_squared_error', optimizer=adam)\n",
        "  return model\n",
        "\n",
        "# Define regression model\n",
        "model= KerasRegressor(build_fn=create_model_opt, verbose=10, batch_size=100, epochs=100)\n",
        "# Fitting model\n",
        "estimator= model.fit(x_standerdized,y)\n",
        "kfold= KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "results= cross_val_score(model, x_standerdized,y, cv= kfold)\n",
        "print('mse:', results.mean())"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "Epoch 2/100\n",
            "Epoch 3/100\n",
            "Epoch 4/100\n",
            "Epoch 5/100\n",
            "Epoch 6/100\n",
            "Epoch 7/100\n",
            "Epoch 8/100\n",
            "Epoch 9/100\n",
            "Epoch 10/100\n",
            "Epoch 11/100\n",
            "Epoch 12/100\n",
            "Epoch 13/100\n",
            "Epoch 14/100\n",
            "Epoch 15/100\n",
            "Epoch 16/100\n",
            "Epoch 17/100\n",
            "Epoch 18/100\n",
            "Epoch 19/100\n",
            "Epoch 20/100\n",
            "Epoch 21/100\n",
            "Epoch 22/100\n",
            "Epoch 23/100\n",
            "Epoch 24/100\n",
            "Epoch 25/100\n",
            "Epoch 26/100\n",
            "Epoch 27/100\n",
            "Epoch 28/100\n",
            "Epoch 29/100\n",
            "Epoch 30/100\n",
            "Epoch 31/100\n",
            "Epoch 32/100\n",
            "Epoch 33/100\n",
            "Epoch 34/100\n",
            "Epoch 35/100\n",
            "Epoch 36/100\n",
            "Epoch 37/100\n",
            "Epoch 38/100\n",
            "Epoch 39/100\n",
            "Epoch 40/100\n",
            "Epoch 41/100\n",
            "Epoch 42/100\n",
            "Epoch 43/100\n",
            "Epoch 44/100\n",
            "Epoch 45/100\n",
            "Epoch 46/100\n",
            "Epoch 47/100\n",
            "Epoch 48/100\n",
            "Epoch 49/100\n",
            "Epoch 50/100\n",
            "Epoch 51/100\n",
            "Epoch 52/100\n",
            "Epoch 53/100\n",
            "Epoch 54/100\n",
            "Epoch 55/100\n",
            "Epoch 56/100\n",
            "Epoch 57/100\n",
            "Epoch 58/100\n",
            "Epoch 59/100\n",
            "Epoch 60/100\n",
            "Epoch 61/100\n",
            "Epoch 62/100\n",
            "Epoch 63/100\n",
            "Epoch 64/100\n",
            "Epoch 65/100\n",
            "Epoch 66/100\n",
            "Epoch 67/100\n",
            "Epoch 68/100\n",
            "Epoch 69/100\n",
            "Epoch 70/100\n",
            "Epoch 71/100\n",
            "Epoch 72/100\n",
            "Epoch 73/100\n",
            "Epoch 74/100\n",
            "Epoch 75/100\n",
            "Epoch 76/100\n",
            "Epoch 77/100\n",
            "Epoch 78/100\n",
            "Epoch 79/100\n",
            "Epoch 80/100\n",
            "Epoch 81/100\n",
            "Epoch 82/100\n",
            "Epoch 83/100\n",
            "Epoch 84/100\n",
            "Epoch 85/100\n",
            "Epoch 86/100\n",
            "Epoch 87/100\n",
            "Epoch 88/100\n",
            "Epoch 89/100\n",
            "Epoch 90/100\n",
            "Epoch 91/100\n",
            "Epoch 92/100\n",
            "Epoch 93/100\n",
            "Epoch 94/100\n",
            "Epoch 95/100\n",
            "Epoch 96/100\n",
            "Epoch 97/100\n",
            "Epoch 98/100\n",
            "Epoch 99/100\n",
            "Epoch 100/100\n",
            "Epoch 1/100\n",
            "Epoch 2/100\n",
            "Epoch 3/100\n",
            "Epoch 4/100\n",
            "Epoch 5/100\n",
            "Epoch 6/100\n",
            "Epoch 7/100\n",
            "Epoch 8/100\n",
            "Epoch 9/100\n",
            "Epoch 10/100\n",
            "Epoch 11/100\n",
            "Epoch 12/100\n",
            "Epoch 13/100\n",
            "Epoch 14/100\n",
            "Epoch 15/100\n",
            "Epoch 16/100\n",
            "Epoch 17/100\n",
            "Epoch 18/100\n",
            "Epoch 19/100\n",
            "Epoch 20/100\n",
            "Epoch 21/100\n",
            "Epoch 22/100\n",
            "Epoch 23/100\n",
            "Epoch 24/100\n",
            "Epoch 25/100\n",
            "Epoch 26/100\n",
            "Epoch 27/100\n",
            "Epoch 28/100\n",
            "Epoch 29/100\n",
            "Epoch 30/100\n",
            "Epoch 31/100\n",
            "Epoch 32/100\n",
            "Epoch 33/100\n",
            "Epoch 34/100\n",
            "Epoch 35/100\n",
            "Epoch 36/100\n",
            "Epoch 37/100\n",
            "Epoch 38/100\n",
            "Epoch 39/100\n",
            "Epoch 40/100\n",
            "Epoch 41/100\n",
            "Epoch 42/100\n",
            "Epoch 43/100\n",
            "Epoch 44/100\n",
            "Epoch 45/100\n",
            "Epoch 46/100\n",
            "Epoch 47/100\n",
            "Epoch 48/100\n",
            "Epoch 49/100\n",
            "Epoch 50/100\n",
            "Epoch 51/100\n",
            "Epoch 52/100\n",
            "Epoch 53/100\n",
            "Epoch 54/100\n",
            "Epoch 55/100\n",
            "Epoch 56/100\n",
            "Epoch 57/100\n",
            "Epoch 58/100\n",
            "Epoch 59/100\n",
            "Epoch 60/100\n",
            "Epoch 61/100\n",
            "Epoch 62/100\n",
            "Epoch 63/100\n",
            "Epoch 64/100\n",
            "Epoch 65/100\n",
            "Epoch 66/100\n",
            "Epoch 67/100\n",
            "Epoch 68/100\n",
            "Epoch 69/100\n",
            "Epoch 70/100\n",
            "Epoch 71/100\n",
            "Epoch 72/100\n",
            "Epoch 73/100\n",
            "Epoch 74/100\n",
            "Epoch 75/100\n",
            "Epoch 76/100\n",
            "Epoch 77/100\n",
            "Epoch 78/100\n",
            "Epoch 79/100\n",
            "Epoch 80/100\n",
            "Epoch 81/100\n",
            "Epoch 82/100\n",
            "Epoch 83/100\n",
            "Epoch 84/100\n",
            "Epoch 85/100\n",
            "Epoch 86/100\n",
            "Epoch 87/100\n",
            "Epoch 88/100\n",
            "Epoch 89/100\n",
            "Epoch 90/100\n",
            "Epoch 91/100\n",
            "Epoch 92/100\n",
            "Epoch 93/100\n",
            "Epoch 94/100\n",
            "Epoch 95/100\n",
            "Epoch 96/100\n",
            "Epoch 97/100\n",
            "Epoch 98/100\n",
            "Epoch 99/100\n",
            "Epoch 100/100\n",
            "Epoch 1/100\n",
            "Epoch 2/100\n",
            "Epoch 3/100\n",
            "Epoch 4/100\n",
            "Epoch 5/100\n",
            "Epoch 6/100\n",
            "Epoch 7/100\n",
            "Epoch 8/100\n",
            "Epoch 9/100\n",
            "Epoch 10/100\n",
            "Epoch 11/100\n",
            "Epoch 12/100\n",
            "Epoch 13/100\n",
            "Epoch 14/100\n",
            "Epoch 15/100\n",
            "Epoch 16/100\n",
            "Epoch 17/100\n",
            "Epoch 18/100\n",
            "Epoch 19/100\n",
            "Epoch 20/100\n",
            "Epoch 21/100\n",
            "Epoch 22/100\n",
            "Epoch 23/100\n",
            "Epoch 24/100\n",
            "Epoch 25/100\n",
            "Epoch 26/100\n",
            "Epoch 27/100\n",
            "Epoch 28/100\n",
            "Epoch 29/100\n",
            "Epoch 30/100\n",
            "Epoch 31/100\n",
            "Epoch 32/100\n",
            "Epoch 33/100\n",
            "Epoch 34/100\n",
            "Epoch 35/100\n",
            "Epoch 36/100\n",
            "Epoch 37/100\n",
            "Epoch 38/100\n",
            "Epoch 39/100\n",
            "Epoch 40/100\n",
            "Epoch 41/100\n",
            "Epoch 42/100\n",
            "Epoch 43/100\n",
            "Epoch 44/100\n",
            "Epoch 45/100\n",
            "Epoch 46/100\n",
            "Epoch 47/100\n",
            "Epoch 48/100\n",
            "Epoch 49/100\n",
            "Epoch 50/100\n",
            "Epoch 51/100\n",
            "Epoch 52/100\n",
            "Epoch 53/100\n",
            "Epoch 54/100\n",
            "Epoch 55/100\n",
            "Epoch 56/100\n",
            "Epoch 57/100\n",
            "Epoch 58/100\n",
            "Epoch 59/100\n",
            "Epoch 60/100\n",
            "Epoch 61/100\n",
            "Epoch 62/100\n",
            "Epoch 63/100\n",
            "Epoch 64/100\n",
            "Epoch 65/100\n",
            "Epoch 66/100\n",
            "Epoch 67/100\n",
            "Epoch 68/100\n",
            "Epoch 69/100\n",
            "Epoch 70/100\n",
            "Epoch 71/100\n",
            "Epoch 72/100\n",
            "Epoch 73/100\n",
            "Epoch 74/100\n",
            "Epoch 75/100\n",
            "Epoch 76/100\n",
            "Epoch 77/100\n",
            "Epoch 78/100\n",
            "Epoch 79/100\n",
            "Epoch 80/100\n",
            "Epoch 81/100\n",
            "Epoch 82/100\n",
            "Epoch 83/100\n",
            "Epoch 84/100\n",
            "Epoch 85/100\n",
            "Epoch 86/100\n",
            "Epoch 87/100\n",
            "Epoch 88/100\n",
            "Epoch 89/100\n",
            "Epoch 90/100\n",
            "Epoch 91/100\n",
            "Epoch 92/100\n",
            "Epoch 93/100\n",
            "Epoch 94/100\n",
            "Epoch 95/100\n",
            "Epoch 96/100\n",
            "Epoch 97/100\n",
            "Epoch 98/100\n",
            "Epoch 99/100\n",
            "Epoch 100/100\n",
            "Epoch 1/100\n",
            "Epoch 2/100\n",
            "Epoch 3/100\n",
            "Epoch 4/100\n",
            "Epoch 5/100\n",
            "Epoch 6/100\n",
            "Epoch 7/100\n",
            "Epoch 8/100\n",
            "Epoch 9/100\n",
            "Epoch 10/100\n",
            "Epoch 11/100\n",
            "Epoch 12/100\n",
            "Epoch 13/100\n",
            "Epoch 14/100\n",
            "Epoch 15/100\n",
            "Epoch 16/100\n",
            "Epoch 17/100\n",
            "Epoch 18/100\n",
            "Epoch 19/100\n",
            "Epoch 20/100\n",
            "Epoch 21/100\n",
            "Epoch 22/100\n",
            "Epoch 23/100\n",
            "Epoch 24/100\n",
            "Epoch 25/100\n",
            "Epoch 26/100\n",
            "Epoch 27/100\n",
            "Epoch 28/100\n",
            "Epoch 29/100\n",
            "Epoch 30/100\n",
            "Epoch 31/100\n",
            "Epoch 32/100\n",
            "Epoch 33/100\n",
            "Epoch 34/100\n",
            "Epoch 35/100\n",
            "Epoch 36/100\n",
            "Epoch 37/100\n",
            "Epoch 38/100\n",
            "Epoch 39/100\n",
            "Epoch 40/100\n",
            "Epoch 41/100\n",
            "Epoch 42/100\n",
            "Epoch 43/100\n",
            "Epoch 44/100\n",
            "Epoch 45/100\n",
            "Epoch 46/100\n",
            "Epoch 47/100\n",
            "Epoch 48/100\n",
            "Epoch 49/100\n",
            "Epoch 50/100\n",
            "Epoch 51/100\n",
            "Epoch 52/100\n",
            "Epoch 53/100\n",
            "Epoch 54/100\n",
            "Epoch 55/100\n",
            "Epoch 56/100\n",
            "Epoch 57/100\n",
            "Epoch 58/100\n",
            "Epoch 59/100\n",
            "Epoch 60/100\n",
            "Epoch 61/100\n",
            "Epoch 62/100\n",
            "Epoch 63/100\n",
            "Epoch 64/100\n",
            "Epoch 65/100\n",
            "Epoch 66/100\n",
            "Epoch 67/100\n",
            "Epoch 68/100\n",
            "Epoch 69/100\n",
            "Epoch 70/100\n",
            "Epoch 71/100\n",
            "Epoch 72/100\n",
            "Epoch 73/100\n",
            "Epoch 74/100\n",
            "Epoch 75/100\n",
            "Epoch 76/100\n",
            "Epoch 77/100\n",
            "Epoch 78/100\n",
            "Epoch 79/100\n",
            "Epoch 80/100\n",
            "Epoch 81/100\n",
            "Epoch 82/100\n",
            "Epoch 83/100\n",
            "Epoch 84/100\n",
            "Epoch 85/100\n",
            "Epoch 86/100\n",
            "Epoch 87/100\n",
            "Epoch 88/100\n",
            "Epoch 89/100\n",
            "Epoch 90/100\n",
            "Epoch 91/100\n",
            "Epoch 92/100\n",
            "Epoch 93/100\n",
            "Epoch 94/100\n",
            "Epoch 95/100\n",
            "Epoch 96/100\n",
            "Epoch 97/100\n",
            "Epoch 98/100\n",
            "Epoch 99/100\n",
            "Epoch 100/100\n",
            "Epoch 1/100\n",
            "Epoch 2/100\n",
            "Epoch 3/100\n",
            "Epoch 4/100\n",
            "Epoch 5/100\n",
            "Epoch 6/100\n",
            "Epoch 7/100\n",
            "Epoch 8/100\n",
            "Epoch 9/100\n",
            "Epoch 10/100\n",
            "Epoch 11/100\n",
            "Epoch 12/100\n",
            "Epoch 13/100\n",
            "Epoch 14/100\n",
            "Epoch 15/100\n",
            "Epoch 16/100\n",
            "Epoch 17/100\n",
            "Epoch 18/100\n",
            "Epoch 19/100\n",
            "Epoch 20/100\n",
            "Epoch 21/100\n",
            "Epoch 22/100\n",
            "Epoch 23/100\n",
            "Epoch 24/100\n",
            "Epoch 25/100\n",
            "Epoch 26/100\n",
            "Epoch 27/100\n",
            "Epoch 28/100\n",
            "Epoch 29/100\n",
            "Epoch 30/100\n",
            "Epoch 31/100\n",
            "Epoch 32/100\n",
            "Epoch 33/100\n",
            "Epoch 34/100\n",
            "Epoch 35/100\n",
            "Epoch 36/100\n",
            "Epoch 37/100\n",
            "Epoch 38/100\n",
            "Epoch 39/100\n",
            "Epoch 40/100\n",
            "Epoch 41/100\n",
            "Epoch 42/100\n",
            "Epoch 43/100\n",
            "Epoch 44/100\n",
            "Epoch 45/100\n",
            "Epoch 46/100\n",
            "Epoch 47/100\n",
            "Epoch 48/100\n",
            "Epoch 49/100\n",
            "Epoch 50/100\n",
            "Epoch 51/100\n",
            "Epoch 52/100\n",
            "Epoch 53/100\n",
            "Epoch 54/100\n",
            "Epoch 55/100\n",
            "Epoch 56/100\n",
            "Epoch 57/100\n",
            "Epoch 58/100\n",
            "Epoch 59/100\n",
            "Epoch 60/100\n",
            "Epoch 61/100\n",
            "Epoch 62/100\n",
            "Epoch 63/100\n",
            "Epoch 64/100\n",
            "Epoch 65/100\n",
            "Epoch 66/100\n",
            "Epoch 67/100\n",
            "Epoch 68/100\n",
            "Epoch 69/100\n",
            "Epoch 70/100\n",
            "Epoch 71/100\n",
            "Epoch 72/100\n",
            "Epoch 73/100\n",
            "Epoch 74/100\n",
            "Epoch 75/100\n",
            "Epoch 76/100\n",
            "Epoch 77/100\n",
            "Epoch 78/100\n",
            "Epoch 79/100\n",
            "Epoch 80/100\n",
            "Epoch 81/100\n",
            "Epoch 82/100\n",
            "Epoch 83/100\n",
            "Epoch 84/100\n",
            "Epoch 85/100\n",
            "Epoch 86/100\n",
            "Epoch 87/100\n",
            "Epoch 88/100\n",
            "Epoch 89/100\n",
            "Epoch 90/100\n",
            "Epoch 91/100\n",
            "Epoch 92/100\n",
            "Epoch 93/100\n",
            "Epoch 94/100\n",
            "Epoch 95/100\n",
            "Epoch 96/100\n",
            "Epoch 97/100\n",
            "Epoch 98/100\n",
            "Epoch 99/100\n",
            "Epoch 100/100\n",
            "Epoch 1/100\n",
            "Epoch 2/100\n",
            "Epoch 3/100\n",
            "Epoch 4/100\n",
            "Epoch 5/100\n",
            "Epoch 6/100\n",
            "Epoch 7/100\n",
            "Epoch 8/100\n",
            "Epoch 9/100\n",
            "Epoch 10/100\n",
            "Epoch 11/100\n",
            "Epoch 12/100\n",
            "Epoch 13/100\n",
            "Epoch 14/100\n",
            "Epoch 15/100\n",
            "Epoch 16/100\n",
            "Epoch 17/100\n",
            "Epoch 18/100\n",
            "Epoch 19/100\n",
            "Epoch 20/100\n",
            "Epoch 21/100\n",
            "Epoch 22/100\n",
            "Epoch 23/100\n",
            "Epoch 24/100\n",
            "Epoch 25/100\n",
            "Epoch 26/100\n",
            "Epoch 27/100\n",
            "Epoch 28/100\n",
            "Epoch 29/100\n",
            "Epoch 30/100\n",
            "Epoch 31/100\n",
            "Epoch 32/100\n",
            "Epoch 33/100\n",
            "Epoch 34/100\n",
            "Epoch 35/100\n",
            "Epoch 36/100\n",
            "Epoch 37/100\n",
            "Epoch 38/100\n",
            "Epoch 39/100\n",
            "Epoch 40/100\n",
            "Epoch 41/100\n",
            "Epoch 42/100\n",
            "Epoch 43/100\n",
            "Epoch 44/100\n",
            "Epoch 45/100\n",
            "Epoch 46/100\n",
            "Epoch 47/100\n",
            "Epoch 48/100\n",
            "Epoch 49/100\n",
            "Epoch 50/100\n",
            "Epoch 51/100\n",
            "Epoch 52/100\n",
            "Epoch 53/100\n",
            "Epoch 54/100\n",
            "Epoch 55/100\n",
            "Epoch 56/100\n",
            "Epoch 57/100\n",
            "Epoch 58/100\n",
            "Epoch 59/100\n",
            "Epoch 60/100\n",
            "Epoch 61/100\n",
            "Epoch 62/100\n",
            "Epoch 63/100\n",
            "Epoch 64/100\n",
            "Epoch 65/100\n",
            "Epoch 66/100\n",
            "Epoch 67/100\n",
            "Epoch 68/100\n",
            "Epoch 69/100\n",
            "Epoch 70/100\n",
            "Epoch 71/100\n",
            "Epoch 72/100\n",
            "Epoch 73/100\n",
            "Epoch 74/100\n",
            "Epoch 75/100\n",
            "Epoch 76/100\n",
            "Epoch 77/100\n",
            "Epoch 78/100\n",
            "Epoch 79/100\n",
            "Epoch 80/100\n",
            "Epoch 81/100\n",
            "Epoch 82/100\n",
            "Epoch 83/100\n",
            "Epoch 84/100\n",
            "Epoch 85/100\n",
            "Epoch 86/100\n",
            "Epoch 87/100\n",
            "Epoch 88/100\n",
            "Epoch 89/100\n",
            "Epoch 90/100\n",
            "Epoch 91/100\n",
            "Epoch 92/100\n",
            "Epoch 93/100\n",
            "Epoch 94/100\n",
            "Epoch 95/100\n",
            "Epoch 96/100\n",
            "Epoch 97/100\n",
            "Epoch 98/100\n",
            "Epoch 99/100\n",
            "Epoch 100/100\n",
            "Epoch 1/100\n",
            "Epoch 2/100\n",
            "Epoch 3/100\n",
            "Epoch 4/100\n",
            "Epoch 5/100\n",
            "Epoch 6/100\n",
            "Epoch 7/100\n",
            "Epoch 8/100\n",
            "Epoch 9/100\n",
            "Epoch 10/100\n",
            "Epoch 11/100\n",
            "Epoch 12/100\n",
            "Epoch 13/100\n",
            "Epoch 14/100\n",
            "Epoch 15/100\n",
            "Epoch 16/100\n",
            "Epoch 17/100\n",
            "Epoch 18/100\n",
            "Epoch 19/100\n",
            "Epoch 20/100\n",
            "Epoch 21/100\n",
            "Epoch 22/100\n",
            "Epoch 23/100\n",
            "Epoch 24/100\n",
            "Epoch 25/100\n",
            "Epoch 26/100\n",
            "Epoch 27/100\n",
            "Epoch 28/100\n",
            "Epoch 29/100\n",
            "Epoch 30/100\n",
            "Epoch 31/100\n",
            "Epoch 32/100\n",
            "Epoch 33/100\n",
            "Epoch 34/100\n",
            "Epoch 35/100\n",
            "Epoch 36/100\n",
            "Epoch 37/100\n",
            "Epoch 38/100\n",
            "Epoch 39/100\n",
            "Epoch 40/100\n",
            "Epoch 41/100\n",
            "Epoch 42/100\n",
            "Epoch 43/100\n",
            "Epoch 44/100\n",
            "Epoch 45/100\n",
            "Epoch 46/100\n",
            "Epoch 47/100\n",
            "Epoch 48/100\n",
            "Epoch 49/100\n",
            "Epoch 50/100\n",
            "Epoch 51/100\n",
            "Epoch 52/100\n",
            "Epoch 53/100\n",
            "Epoch 54/100\n",
            "Epoch 55/100\n",
            "Epoch 56/100\n",
            "Epoch 57/100\n",
            "Epoch 58/100\n",
            "Epoch 59/100\n",
            "Epoch 60/100\n",
            "Epoch 61/100\n",
            "Epoch 62/100\n",
            "Epoch 63/100\n",
            "Epoch 64/100\n",
            "Epoch 65/100\n",
            "Epoch 66/100\n",
            "Epoch 67/100\n",
            "Epoch 68/100\n",
            "Epoch 69/100\n",
            "Epoch 70/100\n",
            "Epoch 71/100\n",
            "Epoch 72/100\n",
            "Epoch 73/100\n",
            "Epoch 74/100\n",
            "Epoch 75/100\n",
            "Epoch 76/100\n",
            "Epoch 77/100\n",
            "Epoch 78/100\n",
            "Epoch 79/100\n",
            "Epoch 80/100\n",
            "Epoch 81/100\n",
            "Epoch 82/100\n",
            "Epoch 83/100\n",
            "Epoch 84/100\n",
            "Epoch 85/100\n",
            "Epoch 86/100\n",
            "Epoch 87/100\n",
            "Epoch 88/100\n",
            "Epoch 89/100\n",
            "Epoch 90/100\n",
            "Epoch 91/100\n",
            "Epoch 92/100\n",
            "Epoch 93/100\n",
            "Epoch 94/100\n",
            "Epoch 95/100\n",
            "Epoch 96/100\n",
            "Epoch 97/100\n",
            "Epoch 98/100\n",
            "Epoch 99/100\n",
            "Epoch 100/100\n",
            "Epoch 1/100\n",
            "Epoch 2/100\n",
            "Epoch 3/100\n",
            "Epoch 4/100\n",
            "Epoch 5/100\n",
            "Epoch 6/100\n",
            "Epoch 7/100\n",
            "Epoch 8/100\n",
            "Epoch 9/100\n",
            "Epoch 10/100\n",
            "Epoch 11/100\n",
            "Epoch 12/100\n",
            "Epoch 13/100\n",
            "Epoch 14/100\n",
            "Epoch 15/100\n",
            "Epoch 16/100\n",
            "Epoch 17/100\n",
            "Epoch 18/100\n",
            "Epoch 19/100\n",
            "Epoch 20/100\n",
            "Epoch 21/100\n",
            "Epoch 22/100\n",
            "Epoch 23/100\n",
            "Epoch 24/100\n",
            "Epoch 25/100\n",
            "Epoch 26/100\n",
            "Epoch 27/100\n",
            "Epoch 28/100\n",
            "Epoch 29/100\n",
            "Epoch 30/100\n",
            "Epoch 31/100\n",
            "Epoch 32/100\n",
            "Epoch 33/100\n",
            "Epoch 34/100\n",
            "Epoch 35/100\n",
            "Epoch 36/100\n",
            "Epoch 37/100\n",
            "Epoch 38/100\n",
            "Epoch 39/100\n",
            "Epoch 40/100\n",
            "Epoch 41/100\n",
            "Epoch 42/100\n",
            "Epoch 43/100\n",
            "Epoch 44/100\n",
            "Epoch 45/100\n",
            "Epoch 46/100\n",
            "Epoch 47/100\n",
            "Epoch 48/100\n",
            "Epoch 49/100\n",
            "Epoch 50/100\n",
            "Epoch 51/100\n",
            "Epoch 52/100\n",
            "Epoch 53/100\n",
            "Epoch 54/100\n",
            "Epoch 55/100\n",
            "Epoch 56/100\n",
            "Epoch 57/100\n",
            "Epoch 58/100\n",
            "Epoch 59/100\n",
            "Epoch 60/100\n",
            "Epoch 61/100\n",
            "Epoch 62/100\n",
            "Epoch 63/100\n",
            "Epoch 64/100\n",
            "Epoch 65/100\n",
            "Epoch 66/100\n",
            "Epoch 67/100\n",
            "Epoch 68/100\n",
            "Epoch 69/100\n",
            "Epoch 70/100\n",
            "Epoch 71/100\n",
            "Epoch 72/100\n",
            "Epoch 73/100\n",
            "Epoch 74/100\n",
            "Epoch 75/100\n",
            "Epoch 76/100\n",
            "Epoch 77/100\n",
            "Epoch 78/100\n",
            "Epoch 79/100\n",
            "Epoch 80/100\n",
            "Epoch 81/100\n",
            "Epoch 82/100\n",
            "Epoch 83/100\n",
            "Epoch 84/100\n",
            "Epoch 85/100\n",
            "Epoch 86/100\n",
            "Epoch 87/100\n",
            "Epoch 88/100\n",
            "Epoch 89/100\n",
            "Epoch 90/100\n",
            "Epoch 91/100\n",
            "Epoch 92/100\n",
            "Epoch 93/100\n",
            "Epoch 94/100\n",
            "Epoch 95/100\n",
            "Epoch 96/100\n",
            "Epoch 97/100\n",
            "Epoch 98/100\n",
            "Epoch 99/100\n",
            "Epoch 100/100\n",
            "Epoch 1/100\n",
            "Epoch 2/100\n",
            "Epoch 3/100\n",
            "Epoch 4/100\n",
            "Epoch 5/100\n",
            "Epoch 6/100\n",
            "Epoch 7/100\n",
            "Epoch 8/100\n",
            "Epoch 9/100\n",
            "Epoch 10/100\n",
            "Epoch 11/100\n",
            "Epoch 12/100\n",
            "Epoch 13/100\n",
            "Epoch 14/100\n",
            "Epoch 15/100\n",
            "Epoch 16/100\n",
            "Epoch 17/100\n",
            "Epoch 18/100\n",
            "Epoch 19/100\n",
            "Epoch 20/100\n",
            "Epoch 21/100\n",
            "Epoch 22/100\n",
            "Epoch 23/100\n",
            "Epoch 24/100\n",
            "Epoch 25/100\n",
            "Epoch 26/100\n",
            "Epoch 27/100\n",
            "Epoch 28/100\n",
            "Epoch 29/100\n",
            "Epoch 30/100\n",
            "Epoch 31/100\n",
            "Epoch 32/100\n",
            "Epoch 33/100\n",
            "Epoch 34/100\n",
            "Epoch 35/100\n",
            "Epoch 36/100\n",
            "Epoch 37/100\n",
            "Epoch 38/100\n",
            "Epoch 39/100\n",
            "Epoch 40/100\n",
            "Epoch 41/100\n",
            "Epoch 42/100\n",
            "Epoch 43/100\n",
            "Epoch 44/100\n",
            "Epoch 45/100\n",
            "Epoch 46/100\n",
            "Epoch 47/100\n",
            "Epoch 48/100\n",
            "Epoch 49/100\n",
            "Epoch 50/100\n",
            "Epoch 51/100\n",
            "Epoch 52/100\n",
            "Epoch 53/100\n",
            "Epoch 54/100\n",
            "Epoch 55/100\n",
            "Epoch 56/100\n",
            "Epoch 57/100\n",
            "Epoch 58/100\n",
            "Epoch 59/100\n",
            "Epoch 60/100\n",
            "Epoch 61/100\n",
            "Epoch 62/100\n",
            "Epoch 63/100\n",
            "Epoch 64/100\n",
            "Epoch 65/100\n",
            "Epoch 66/100\n",
            "Epoch 67/100\n",
            "Epoch 68/100\n",
            "Epoch 69/100\n",
            "Epoch 70/100\n",
            "Epoch 71/100\n",
            "Epoch 72/100\n",
            "Epoch 73/100\n",
            "Epoch 74/100\n",
            "Epoch 75/100\n",
            "Epoch 76/100\n",
            "Epoch 77/100\n",
            "Epoch 78/100\n",
            "Epoch 79/100\n",
            "Epoch 80/100\n",
            "Epoch 81/100\n",
            "Epoch 82/100\n",
            "Epoch 83/100\n",
            "Epoch 84/100\n",
            "Epoch 85/100\n",
            "Epoch 86/100\n",
            "Epoch 87/100\n",
            "Epoch 88/100\n",
            "Epoch 89/100\n",
            "Epoch 90/100\n",
            "Epoch 91/100\n",
            "Epoch 92/100\n",
            "Epoch 93/100\n",
            "Epoch 94/100\n",
            "Epoch 95/100\n",
            "Epoch 96/100\n",
            "Epoch 97/100\n",
            "Epoch 98/100\n",
            "Epoch 99/100\n",
            "Epoch 100/100\n",
            "Epoch 1/100\n",
            "Epoch 2/100\n",
            "Epoch 3/100\n",
            "Epoch 4/100\n",
            "Epoch 5/100\n",
            "Epoch 6/100\n",
            "Epoch 7/100\n",
            "Epoch 8/100\n",
            "Epoch 9/100\n",
            "Epoch 10/100\n",
            "Epoch 11/100\n",
            "Epoch 12/100\n",
            "Epoch 13/100\n",
            "Epoch 14/100\n",
            "Epoch 15/100\n",
            "Epoch 16/100\n",
            "Epoch 17/100\n",
            "Epoch 18/100\n",
            "Epoch 19/100\n",
            "Epoch 20/100\n",
            "Epoch 21/100\n",
            "Epoch 22/100\n",
            "Epoch 23/100\n",
            "Epoch 24/100\n",
            "Epoch 25/100\n",
            "Epoch 26/100\n",
            "Epoch 27/100\n",
            "Epoch 28/100\n",
            "Epoch 29/100\n",
            "Epoch 30/100\n",
            "Epoch 31/100\n",
            "Epoch 32/100\n",
            "Epoch 33/100\n",
            "Epoch 34/100\n",
            "Epoch 35/100\n",
            "Epoch 36/100\n",
            "Epoch 37/100\n",
            "Epoch 38/100\n",
            "Epoch 39/100\n",
            "Epoch 40/100\n",
            "Epoch 41/100\n",
            "Epoch 42/100\n",
            "Epoch 43/100\n",
            "Epoch 44/100\n",
            "Epoch 45/100\n",
            "Epoch 46/100\n",
            "Epoch 47/100\n",
            "Epoch 48/100\n",
            "Epoch 49/100\n",
            "Epoch 50/100\n",
            "Epoch 51/100\n",
            "Epoch 52/100\n",
            "Epoch 53/100\n",
            "Epoch 54/100\n",
            "Epoch 55/100\n",
            "Epoch 56/100\n",
            "Epoch 57/100\n",
            "Epoch 58/100\n",
            "Epoch 59/100\n",
            "Epoch 60/100\n",
            "Epoch 61/100\n",
            "Epoch 62/100\n",
            "Epoch 63/100\n",
            "Epoch 64/100\n",
            "Epoch 65/100\n",
            "Epoch 66/100\n",
            "Epoch 67/100\n",
            "Epoch 68/100\n",
            "Epoch 69/100\n",
            "Epoch 70/100\n",
            "Epoch 71/100\n",
            "Epoch 72/100\n",
            "Epoch 73/100\n",
            "Epoch 74/100\n",
            "Epoch 75/100\n",
            "Epoch 76/100\n",
            "Epoch 77/100\n",
            "Epoch 78/100\n",
            "Epoch 79/100\n",
            "Epoch 80/100\n",
            "Epoch 81/100\n",
            "Epoch 82/100\n",
            "Epoch 83/100\n",
            "Epoch 84/100\n",
            "Epoch 85/100\n",
            "Epoch 86/100\n",
            "Epoch 87/100\n",
            "Epoch 88/100\n",
            "Epoch 89/100\n",
            "Epoch 90/100\n",
            "Epoch 91/100\n",
            "Epoch 92/100\n",
            "Epoch 93/100\n",
            "Epoch 94/100\n",
            "Epoch 95/100\n",
            "Epoch 96/100\n",
            "Epoch 97/100\n",
            "Epoch 98/100\n",
            "Epoch 99/100\n",
            "Epoch 100/100\n",
            "Epoch 1/100\n",
            "Epoch 2/100\n",
            "Epoch 3/100\n",
            "Epoch 4/100\n",
            "Epoch 5/100\n",
            "Epoch 6/100\n",
            "Epoch 7/100\n",
            "Epoch 8/100\n",
            "Epoch 9/100\n",
            "Epoch 10/100\n",
            "Epoch 11/100\n",
            "Epoch 12/100\n",
            "Epoch 13/100\n",
            "Epoch 14/100\n",
            "Epoch 15/100\n",
            "Epoch 16/100\n",
            "Epoch 17/100\n",
            "Epoch 18/100\n",
            "Epoch 19/100\n",
            "Epoch 20/100\n",
            "Epoch 21/100\n",
            "Epoch 22/100\n",
            "Epoch 23/100\n",
            "Epoch 24/100\n",
            "Epoch 25/100\n",
            "Epoch 26/100\n",
            "Epoch 27/100\n",
            "Epoch 28/100\n",
            "Epoch 29/100\n",
            "Epoch 30/100\n",
            "Epoch 31/100\n",
            "Epoch 32/100\n",
            "Epoch 33/100\n",
            "Epoch 34/100\n",
            "Epoch 35/100\n",
            "Epoch 36/100\n",
            "Epoch 37/100\n",
            "Epoch 38/100\n",
            "Epoch 39/100\n",
            "Epoch 40/100\n",
            "Epoch 41/100\n",
            "Epoch 42/100\n",
            "Epoch 43/100\n",
            "Epoch 44/100\n",
            "Epoch 45/100\n",
            "Epoch 46/100\n",
            "Epoch 47/100\n",
            "Epoch 48/100\n",
            "Epoch 49/100\n",
            "Epoch 50/100\n",
            "Epoch 51/100\n",
            "Epoch 52/100\n",
            "Epoch 53/100\n",
            "Epoch 54/100\n",
            "Epoch 55/100\n",
            "Epoch 56/100\n",
            "Epoch 57/100\n",
            "Epoch 58/100\n",
            "Epoch 59/100\n",
            "Epoch 60/100\n",
            "Epoch 61/100\n",
            "Epoch 62/100\n",
            "Epoch 63/100\n",
            "Epoch 64/100\n",
            "Epoch 65/100\n",
            "Epoch 66/100\n",
            "Epoch 67/100\n",
            "Epoch 68/100\n",
            "Epoch 69/100\n",
            "Epoch 70/100\n",
            "Epoch 71/100\n",
            "Epoch 72/100\n",
            "Epoch 73/100\n",
            "Epoch 74/100\n",
            "Epoch 75/100\n",
            "Epoch 76/100\n",
            "Epoch 77/100\n",
            "Epoch 78/100\n",
            "Epoch 79/100\n",
            "Epoch 80/100\n",
            "Epoch 81/100\n",
            "Epoch 82/100\n",
            "Epoch 83/100\n",
            "Epoch 84/100\n",
            "Epoch 85/100\n",
            "Epoch 86/100\n",
            "Epoch 87/100\n",
            "Epoch 88/100\n",
            "Epoch 89/100\n",
            "Epoch 90/100\n",
            "Epoch 91/100\n",
            "Epoch 92/100\n",
            "Epoch 93/100\n",
            "Epoch 94/100\n",
            "Epoch 95/100\n",
            "Epoch 96/100\n",
            "Epoch 97/100\n",
            "Epoch 98/100\n",
            "Epoch 99/100\n",
            "Epoch 100/100\n",
            "mse: -0.606938648223877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-f_LPgExQa2",
        "outputId": "5a957450-f62c-43a8-f315-685db29b86e2"
      },
      "source": [
        "print('MSE',results.mean())"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE -0.606938648223877\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}